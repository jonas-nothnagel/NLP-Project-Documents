{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Has to be run with GPU support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basics'''\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('../..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "\n",
    "import pandas as pd\n",
    "import pickle \n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from ipywidgets import IntProgress\n",
    "from tabulate import tabulate\n",
    "import string\n",
    "import re\n",
    "\n",
    "#from simpletransformers.classification import ClassificationModel, ClassificationArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/_hot_topics_clean.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "       'food_and_agricultural_commodities_strategy', 'green_recovery',\n",
    "       'health', 'human_rights', 'leaving_no_one_behind',\n",
    "       'multi_stakeholder_collaboration', 'nature_based_solution', 'no tag',\n",
    "       'plastic', 'poverty_reduction', 'public_private_partnership', 'sids',\n",
    "       'south_south_cooperation', 'structural_system_transformation']\n",
    "\n",
    "\n",
    "remove = ['Unnamed: 4', 'cov_19', 'crisis_setting', 'digital_transformation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 385\n",
      "test size: 165\n"
     ]
    }
   ],
   "source": [
    "# example train df:\n",
    "def create_train_test(data, category):\n",
    "    \n",
    "    df_alpha = pd.DataFrame(data[['all_text_clean', category]]) \n",
    "    df_alpha = df_alpha.rename(columns={\"all_text_clean\": \"text\", category: \"labels\"})\n",
    "    \n",
    "    train_df, eval_df = train_test_split(df_alpha, test_size=0.3)\n",
    "    print('train size:', len(train_df))\n",
    "    print('test size:', len(eval_df))\n",
    "    \n",
    "    return train_df, eval_df\n",
    "\n",
    "train_df, eval_df = create_train_test(df, 'food_and_agricultural_commodities_strategy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline roberta classification with sliding window\n",
    "\n",
    "# Optional model configuration\n",
    "model_args = ClassificationArgs(sliding_window=True, max_seq_length=512)\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel(\n",
    "    \"roberta\", \"roberta-base\", args=model_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.train_model(train_df)\n",
    "\n",
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
    "\n",
    "# Make predictions with the model\n",
    "predictions, raw_outputs = model.predict([\"Sam was a Wizard\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
