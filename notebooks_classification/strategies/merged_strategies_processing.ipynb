{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('../..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import make_dataset as mk\n",
    "\n",
    "import tools as tools\n",
    "\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import data'''\n",
    "\n",
    "main_strategy_1 = pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/main_strategy_1.csv')\n",
    "first_8= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/first_8.csv')\n",
    "second_8= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/second_8.csv')\n",
    "third_8= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/third_8.csv')\n",
    "rest_7= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/rest_7.csv')\n",
    "\n",
    "main_strategy_2= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/main_strategy_2.csv')\n",
    "first_9= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/first_9.csv')\n",
    "second_9= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/second_9.csv')\n",
    "third_9= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/third_9.csv')\n",
    "rest_8= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/rest_8.csv')\n",
    "\n",
    "main_strategy_3= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/main_strategy_3.csv')\n",
    "first_10= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/first_10.csv')\n",
    "second_10= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/second_10.csv')\n",
    "third_10= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/third_10.csv')\n",
    "rest_9= pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/rest_9.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:(10, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capacity_building</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enabling</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>finance_economy</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>food_and_agricultural_commodities</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>governance</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>law_regulation</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>management_operation</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mitigation_adaptation</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>monitor_inventory</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>technology_innovation</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            category  Count\n",
       "0                  capacity_building    113\n",
       "1                           enabling     45\n",
       "2                    finance_economy     32\n",
       "3  food_and_agricultural_commodities     17\n",
       "4                         governance    131\n",
       "5                     law_regulation    120\n",
       "6               management_operation    104\n",
       "7              mitigation_adaptation      3\n",
       "8                  monitor_inventory     63\n",
       "9              technology_innovation     20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:(11, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capacity_building</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enabling</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance_economy</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food_and_agricultural_commodities</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>governance</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>law_regulation</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>management_operation</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mitigation_adaptation</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>monitor_inventory</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>technology_innovation</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             category  Count\n",
       "0                          Unnamed: 4      4\n",
       "1                   capacity_building    142\n",
       "2                            enabling     20\n",
       "3                     finance_economy     56\n",
       "4   food_and_agricultural_commodities     27\n",
       "5                          governance     93\n",
       "6                      law_regulation    115\n",
       "7                management_operation     89\n",
       "8               mitigation_adaptation     22\n",
       "9                   monitor_inventory     54\n",
       "10              technology_innovation     26"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:(11, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unnamed: 4</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>capacity_building</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>enabling</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finance_economy</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>food_and_agricultural_commodities</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>governance</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>law_regulation</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>management_operation</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mitigation_adaptation</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>monitor_inventory</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>technology_innovation</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             category  Count\n",
       "0                          Unnamed: 4     78\n",
       "1                   capacity_building    163\n",
       "2                            enabling     22\n",
       "3                     finance_economy     81\n",
       "4   food_and_agricultural_commodities     46\n",
       "5                          governance     23\n",
       "6                      law_regulation     27\n",
       "7                management_operation     91\n",
       "8               mitigation_adaptation     21\n",
       "9                   monitor_inventory     61\n",
       "10              technology_innovation     35"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''count and re-process labels'''\n",
    "main_strategy_1, df_lambda_ms_1 = tools.count_labels(main_strategy_1)\n",
    "main_strategy_2, df_lambda_ms_2 = tools.count_labels(main_strategy_2)\n",
    "main_strategy_3, df_lambda_ms_3 = tools.count_labels(main_strategy_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with non-existing categories:\n",
    "strategies = ['capacity_building', 'enabling',  'finance_economy',\n",
    "       'food_and_agricultural_commodities', 'governance', 'law_regulation',\n",
    "       'management_operation', 'mitigation_adaptation', 'monitor_inventory','technology_innovation']\n",
    "\n",
    "main_strategy_1 = main_strategy_1[main_strategy_1['category'].isin(strategies)]\n",
    "main_strategy_2 = main_strategy_2[main_strategy_2['category'].isin(strategies)]\n",
    "main_strategy_3 = main_strategy_3[main_strategy_3['category'].isin(strategies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant = main_strategy_1[['PIMS_ID', 'capacity_building', 'enabling',  'finance_economy',\n",
    "       'food_and_agricultural_commodities', 'governance', 'law_regulation',\n",
    "       'management_operation', 'mitigation_adaptation', 'monitor_inventory','technology_innovation', 'category']]\n",
    "\n",
    "relevant.rename({'category':'category_1'}, axis = 1, inplace = True)\n",
    "              \n",
    "result = pd.concat([relevant, main_strategy_2['category']], axis=1, sort=False)\n",
    "result.rename({'category':'category_2'}, axis = 1, inplace = True)\n",
    "\n",
    "result = pd.concat([result, main_strategy_3['category']], axis=1, sort=False)\n",
    "result.rename({'category':'category_3'}, axis = 1, inplace = True)\n",
    "\n",
    "# turn to multi_label problem\n",
    "\n",
    "result[['capacity_building', 'enabling',  'finance_economy',\n",
    "       'food_and_agricultural_commodities', 'governance', 'law_regulation',\n",
    "       'management_operation', 'mitigation_adaptation', 'monitor_inventory','technology_innovation']] = result[['capacity_building', 'enabling',  'finance_economy',\n",
    "       'food_and_agricultural_commodities', 'governance', 'law_regulation',\n",
    "       'management_operation', 'mitigation_adaptation', 'monitor_inventory','technology_innovation']].fillna(0).astype(int)\n",
    "\n",
    "def to_multi_label(dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "\n",
    "        for column in dataframe.columns:\n",
    "\n",
    "            if row['category_2'] == column:\n",
    "\n",
    "                if row[column] == 0:\n",
    "                    dataframe.at[index, column] = 1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            if row['category_3'] == column:\n",
    "\n",
    "                if row[column] == 0:\n",
    "                    dataframe.at[index, column] = 1\n",
    "            else:\n",
    "                pass \n",
    "    \n",
    "    \n",
    "    dataframe['labels']= dataframe[['capacity_building', 'enabling',  'finance_economy',\n",
    "       'food_and_agricultural_commodities', 'governance', 'law_regulation',\n",
    "       'management_operation', 'mitigation_adaptation', 'monitor_inventory','technology_innovation']].fillna(0).astype(int).values.tolist()\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "to_multi_label(result)\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''first triplet'''\n",
    "\n",
    "land_num_1 = first_8._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy'])\n",
    "\n",
    "land_num_2 = second_8._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = third_8._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "\n",
    "sub_category_1 = sub_category    \n",
    "#sub_category = sub_category.drop(columns=['PIMS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''second triplet'''\n",
    "\n",
    "land_num_1 = first_9._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_2 = second_9._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = third_9._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy','Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "\n",
    "sub_category_2 = sub_category    \n",
    "#sub_category_2 = sub_category.drop(columns=['PIMS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''third triplet'''\n",
    "\n",
    "land_num_1 = first_10._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_2 = second_10._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = third_10._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "\n",
    "sub_category_3 = sub_category       \n",
    "#sub_category_3 = sub_category.drop(columns=['PIMS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''fourth triplet'''\n",
    "\n",
    "land_num_1 = rest_7._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_2 = rest_8._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = rest_9._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "sub_category_4 = sub_category    \n",
    "#sub_category_4 = sub_category.drop(columns=['PIMS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merge first three triplets'''\n",
    "'''fourth triplet'''\n",
    "\n",
    "land_num_1 = sub_category_1._get_numeric_data()\n",
    "land_num_df_1 = land_num_1\n",
    "\n",
    "land_num_2 = sub_category_2._get_numeric_data()\n",
    "land_num_df_2 = land_num_2\n",
    "\n",
    "land_num_3 = sub_category_3._get_numeric_data()\n",
    "land_num_df_3 = land_num_3\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "sub_category_all_1 = sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_num_1 = sub_category_4._get_numeric_data()\n",
    "df_num_1_1 = df_num_1\n",
    "df_num_2 = sub_category_all_1._get_numeric_data()\n",
    "df_num_2_1 = df_num_2\n",
    "\n",
    "\n",
    "'''combine lists'''\n",
    "df_num_1 = df_num_1.drop(columns=['PIMS_ID'])\n",
    "df_num_2 = df_num_2.drop(columns=['PIMS_ID'])\n",
    "sub_sub_1 = df_num_1.columns.tolist()\n",
    "sub_sub_2 = df_num_2.columns.tolist()\n",
    "sub_sub = sub_sub_1 + list(set(sub_sub_2) - set(sub_sub_1))\n",
    "\n",
    "unmatched_items_1 = [d for d in sub_sub_1 if d not in sub_sub_2]\n",
    "unmatched_items_2 = [d for d in sub_sub_2 if d not in sub_sub_1]\n",
    "\n",
    "for col in unmatched_items_1:\n",
    "    df_num_2_1[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2:\n",
    "    df_num_1_1[col] = 0\n",
    "    \n",
    "sub_category = df_num_1_1.merge(df_num_2_1, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub_sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub_sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "sub_strategies = sub_category.drop(columns=['PIMS_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merge with main strategies'''\n",
    "strategies = result.drop(columns=['category_1', 'category_2', 'category_3', 'labels'])\n",
    "strategies = pd.concat([strategies, sub_strategies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merge with one of the cleaned dataframes'''\n",
    "df = pd.read_csv(os.path.abspath(os.path.join('../..', 'data/processed/'))+\"/technical_team.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['PIMS_ID', 'all_text_clean', 'all_text_clean_spacy']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = df.merge(strategies, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "strategy.to_csv(os.path.abspath(os.path.join('../..', 'data/processed/'))+\"/strategies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''first triplet'''\n",
    "\n",
    "land_num_1 = first_8._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy'])\n",
    "\n",
    "land_num_2 = second_8._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = third_8._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "df_num_1 = sub_category._get_numeric_data()\n",
    "df_num_1_1 = df_num_1\n",
    "df_num_2 = rest_7._get_numeric_data()\n",
    "df_num_2_1 = df_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "\n",
    "'''combine lists'''\n",
    "df_num_1 = df_num_1_1.drop(columns=['PIMS_ID'])\n",
    "df_num_2 = df_num_2_1.drop(columns=['PIMS_ID'])\n",
    "sub_sub_1 = df_num_1.columns.tolist()\n",
    "sub_sub_2 = df_num_2.columns.tolist()\n",
    "sub_sub = sub_sub_1 + list(set(sub_sub_2) - set(sub_sub_1))\n",
    "\n",
    "unmatched_items_1 = [d for d in sub_sub_1 if d not in sub_sub_2]\n",
    "unmatched_items_2 = [d for d in sub_sub_2 if d not in sub_sub_1]\n",
    "\n",
    "for col in unmatched_items_1:\n",
    "    df_num_2_1[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2:\n",
    "    df_num_1_1[col] = 0\n",
    "    \n",
    "sub_category = df_num_1_1.merge(df_num_2_1, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub_sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub_sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "sub_strategis_1 = sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''second triplet'''\n",
    "\n",
    "land_num_1 = first_9._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_2 = second_9._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = third_9._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "df_num_1 = sub_category._get_numeric_data()\n",
    "df_num_1_1 = df_num_1\n",
    "df_num_2 = rest_8._get_numeric_data()\n",
    "df_num_2_1 = df_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "\n",
    "'''combine lists'''\n",
    "df_num_1 = df_num_1_1.drop(columns=['PIMS_ID'])\n",
    "df_num_2 = df_num_2_1.drop(columns=['PIMS_ID'])\n",
    "sub_sub_1 = df_num_1.columns.tolist()\n",
    "sub_sub_2 = df_num_2.columns.tolist()\n",
    "sub_sub = sub_sub_1 + list(set(sub_sub_2) - set(sub_sub_1))\n",
    "\n",
    "unmatched_items_1 = [d for d in sub_sub_1 if d not in sub_sub_2]\n",
    "unmatched_items_2 = [d for d in sub_sub_2 if d not in sub_sub_1]\n",
    "\n",
    "for col in unmatched_items_1:\n",
    "    df_num_2_1[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2:\n",
    "    df_num_1_1[col] = 0\n",
    "    \n",
    "sub_category = df_num_1_1.merge(df_num_2_1, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub_sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub_sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "sub_strategis_2 = sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''second triplet'''\n",
    "\n",
    "land_num_1 = first_10._get_numeric_data()\n",
    "land_num_df_1 = land_num_1.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_2 = second_10._get_numeric_data()\n",
    "land_num_df_2 = land_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "land_num_3 = third_10._get_numeric_data()\n",
    "land_num_df_3 = land_num_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "'''combine lists'''\n",
    "land_num_1 = land_num_df_1.drop(columns=['PIMS_ID'])\n",
    "land_num_2 = land_num_df_2.drop(columns=['PIMS_ID'])\n",
    "land_num_3 = land_num_df_3.drop(columns=['PIMS_ID'])\n",
    "\n",
    "land_sub_1 = land_num_1.columns.tolist()\n",
    "land_sub_2 = land_num_2.columns.tolist()\n",
    "land_sub_3 = land_num_3.columns.tolist()\n",
    "\n",
    "sub = land_sub_1 + list(set(land_sub_2) - set(land_sub_1))\n",
    "sub = sub + list(set(land_sub_3) - set(sub))\n",
    "\n",
    "unmatched_items_1_2 = [d for d in land_sub_1 if d not in land_sub_2]\n",
    "unmatched_items_1_3 = [d for d in land_sub_1 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_2_1 = [d for d in land_sub_2 if d not in land_sub_1]\n",
    "unmatched_items_2_3 = [d for d in land_sub_2 if d not in land_sub_3]\n",
    "\n",
    "unmatched_items_3_1 = [d for d in land_sub_3 if d not in land_sub_1]\n",
    "unmatched_items_3_2 = [d for d in land_sub_3 if d not in land_sub_2]\n",
    "\n",
    "for col in unmatched_items_1_2:\n",
    "    land_num_df_2[col] = 0\n",
    "for col in unmatched_items_1_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_2_3:\n",
    "    land_num_df_3[col] = 0\n",
    "    \n",
    "    \n",
    "for col in unmatched_items_3_1:\n",
    "    land_num_df_1[col] = 0\n",
    "for col in unmatched_items_3_2:\n",
    "    land_num_df_2[col] = 0\n",
    "    \n",
    "sub_category = land_num_df_1.merge(land_num_df_2, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "sub_category = sub_category.merge(land_num_df_3, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "df_num_1 = sub_category._get_numeric_data()\n",
    "df_num_1_1 = df_num_1\n",
    "df_num_2 = rest_9._get_numeric_data()\n",
    "df_num_2_1 = df_num_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'Unnamed: 4'])\n",
    "\n",
    "\n",
    "'''combine lists'''\n",
    "df_num_1 = df_num_1_1.drop(columns=['PIMS_ID'])\n",
    "df_num_2 = df_num_2_1.drop(columns=['PIMS_ID'])\n",
    "sub_sub_1 = df_num_1.columns.tolist()\n",
    "sub_sub_2 = df_num_2.columns.tolist()\n",
    "sub_sub = sub_sub_1 + list(set(sub_sub_2) - set(sub_sub_1))\n",
    "\n",
    "unmatched_items_1 = [d for d in sub_sub_1 if d not in sub_sub_2]\n",
    "unmatched_items_2 = [d for d in sub_sub_2 if d not in sub_sub_1]\n",
    "\n",
    "for col in unmatched_items_1:\n",
    "    df_num_2_1[col] = 0\n",
    "    \n",
    "for col in unmatched_items_2:\n",
    "    df_num_1_1[col] = 0\n",
    "    \n",
    "sub_category = df_num_1_1.merge(df_num_2_1, how='left', left_on=['PIMS_ID'], right_on=['PIMS_ID'])\n",
    "\n",
    "for index, row in sub_category.iterrows():\n",
    "    for i in sub_sub:          \n",
    "        if row[i+\"_x\"] or row[i+\"_y\"]:\n",
    "            sub_category.at[index, i] = 1\n",
    "        else:\n",
    "            sub_category.at[index, i] = 0     \n",
    "            \n",
    "for i in sub_sub:\n",
    "    sub_category= sub_category.drop(columns=[i+\"_x\"])\n",
    "    sub_category= sub_category.drop(columns=[i+\"_y\"])\n",
    "    \n",
    "sub_strategis_3 = sub_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''merge with main strategies'''\n",
    "strategies = main_strategy_1.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'main_strategy_1','category', 'cat'])\n",
    "strategies_1 = pd.concat([strategies, sub_strategis_1], axis=1)\n",
    "\n",
    "strategies = main_strategy_2.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'main_strategy_2','category', 'cat'])\n",
    "strategies_2 = pd.concat([strategies, sub_strategis_2], axis=1)\n",
    "\n",
    "strategies = main_strategy_3.drop(columns=['all_text_clean', 'all_text_clean_spacy', 'main_strategy_3','category', 'cat'])\n",
    "strategies_3 = pd.concat([strategies, sub_strategis_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategies = ['capacity_building', 'enabling', 'finance_economy',\n",
    "       'food_and_agricultural_commodities', 'governance', 'law_regulation',\n",
    "       'management_operation', 'mitigation_adaptation', 'monitor_inventory',\n",
    "       'technology_innovation']\n",
    "\n",
    "#chemicals_and_waste\n",
    "capacity_building = []\n",
    "enabling = []\n",
    "finance_economy = []\n",
    "food_and_agricultural_commodities = []\n",
    "governance = []\n",
    "law_regulation =[]\n",
    "management_operation = []\n",
    "mitigation_adaptation = []\n",
    "monitor_inventory = []\n",
    "technology_innovation = []\n",
    "\n",
    "lists = [capacity_building,\n",
    "enabling,\n",
    "finance_economy,\n",
    "food_and_agricultural_commodities,\n",
    "governance,\n",
    "law_regulation ,\n",
    "management_operation ,\n",
    "mitigation_adaptation ,\n",
    "monitor_inventory ,\n",
    "technology_innovation]\n",
    "\n",
    "d = dict(zip(strategies, lists))\n",
    "d_1 = dict(zip(strategies, lists))\n",
    "d_2 = dict(zip(strategies, lists))\n",
    "d_3 = dict(zip(strategies, lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in d.items():\n",
    "    for index, row in strategies_1.iterrows():\n",
    "        if row[key] == 1:\n",
    "            for i in range(len(strategies_1.columns)): \n",
    "                if row[i] == 1:\n",
    "                    if row.index[i] not in value:\n",
    "                        value.append(row.index[i])\n",
    "                        \n",
    "    for index, row in strategies_2.iterrows():\n",
    "        if row[key] == 1:\n",
    "            for i in range(len(strategies_2.columns)): \n",
    "                if row[i] == 1:\n",
    "                    if row.index[i] not in value:\n",
    "                        value.append(row.index[i]) \n",
    "                        \n",
    "    for index, row in strategies_3.iterrows():\n",
    "        if row[key] == 1:\n",
    "            for i in range(len(strategies_3.columns)): \n",
    "                if row[i] == 1:\n",
    "                    if row.index[i] not in value:\n",
    "                        value.append(row.index[i])\n",
    "                        \n",
    "for key, value in d.copy().items():\n",
    "    for i in value:\n",
    "        if i == key:\n",
    "            value.remove(i)\n",
    "            \n",
    "with open(os.path.abspath(os.path.join('../..', 'data/processed/'))+\"/strategy_dict.pkl\", 'wb') as handle:\n",
    "    pickle.dump(d, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
