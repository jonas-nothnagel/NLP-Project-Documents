{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('../..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import clean_dataset as clean\n",
    "import make_dataset as mk\n",
    "import vectorize_embed as em\n",
    "import tools as tools\n",
    "import models as m\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "'''features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import joblib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'chemicals_and_waste_programme_x', 'persistent_organic_pollutants',\n",
       "       'ozone_depleting_substances', 'heavy_metals', 'waste_management',\n",
       "       'cooling_alternatives', 'climate_change_adaptation_programme_x',\n",
       "       'climate_information_and_early_warning_systems_ci_ews',\n",
       "       'cross_sectoral_climate_resilient_livelihoods',\n",
       "       'fostering_food_security_and_resilient_agricultural_systems',\n",
       "       'mainstreaming_integrated_policy_and_planning_for_climate_resilient_sustainable_development',\n",
       "       'ecosystem_based_adaptation', 'urban_resilience',\n",
       "       'climate_resilient_integrated_water_resource_and_coastal_management',\n",
       "       'climate_forest_of_climate_change_mitigation_x', 'carbon_sequestration',\n",
       "       'climate_financing_for_redd_redd', 'chemicals_and_waste_programme_y',\n",
       "       'climate_change_adaptation_programme_y',\n",
       "       'climate_forest_of_climate_change_mitigation_y',\n",
       "       'climate_strategies_and_policy_programme',\n",
       "       'ecosystems_and_biodiversity_programme_x',\n",
       "       'energy_program_of_climate_change_mitigation_x',\n",
       "       'oceans_and_water_programme_x', 'environmental_governance_programme_x',\n",
       "       'category_1', 'category_2', 'category_3', 'labels',\n",
       "       'ecosystems_and_biodiversity_programme_y',\n",
       "       'ecosystem_management_and_restoration', 'mainstreaming_biodiversity',\n",
       "       'strengthening_conservation_areas',\n",
       "       'energy_program_of_climate_change_mitigation_y', 'energy_efficiency',\n",
       "       'renewable_energy', 'energy_access', 'miscellaneous_energy_program',\n",
       "       'oceans_and_water_programme_y', 'small_island_dev_states_program_sids',\n",
       "       'climate_resilient_access_to_water_supply_sanitation',\n",
       "       'climate_resilient_integrated_water_resource_coastal_area_management',\n",
       "       'cross_cutting_governance_and_learning',\n",
       "       'protection_of_transboundary_surface_groundwater_resources_in_a_changing_climate',\n",
       "       'sustainable_management_of_oceans_in_a_changing_climate',\n",
       "       'environmental_governance_programme_y', 'mainstreaming_green_economy',\n",
       "       'gcp_green_commodities_programme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import data'''\n",
    "\n",
    "df = pd.read_json(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/technical_team_all.json')  \n",
    "'''lowercase data and str type data'''\n",
    "df['all_text_clean_spacy'] = df['all_text_clean_spacy'].astype(str).apply(clean.basic)\n",
    "df['all_text_clean'] = df['all_text_clean'].astype(str)\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['chemicals_and_waste_programme', 'climate_change_adaptation_programme',\n",
    "       'climate_forest_of_climate_change_mitigation',\n",
    "       'climate_strategies_and_policy_programme',\n",
    "       'ecosystems_and_biodiversity_programme',\n",
    "       'energy_program_of_climate_change_mitigation',\n",
    "       'oceans_and_water_programme', 'environmental_governance_programme',]].sum(axis=0).sort_values(ascending = False).plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['chemicals_and_waste_programme', 'climate_change_adaptation_programme',\n",
    "       'climate_forest_of_climate_change_mitigation',\n",
    "       'climate_strategies_and_policy_programme',\n",
    "       'ecosystems_and_biodiversity_programme',\n",
    "       'energy_program_of_climate_change_mitigation',\n",
    "       'oceans_and_water_programme', 'environmental_governance_programme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over categories and save best models:\n",
    "    #Creating a dict of the models\n",
    "model_dict = {\n",
    "              'LR_balanced' : LogisticRegression(random_state = 3, class_weight = \"balanced\"),\n",
    "              'LR' : LogisticRegression(random_state = 3),\n",
    "              'SDG' : SGDClassifier(random_state=3, loss='log'),\n",
    "              'SDG_balanceed' : SGDClassifier(random_state=3, loss='log',class_weight = \"balanced\" ),\n",
    "              'RF': RandomForestClassifier(random_state=3),\n",
    "              'Decsision_Tree': DecisionTreeClassifier(random_state=3),\n",
    "              'AdaBoost': AdaBoostClassifier(random_state=3),\n",
    "              'GNB': GaussianNB(),\n",
    "              'KNB': KNeighborsClassifier()}\n",
    "    \n",
    "for category in categories: \n",
    "    if category != \"no tag\":\n",
    "        if df[category].sum(axis=0) > 20:\n",
    "            \n",
    "            print('processing:', category)\n",
    "            print('_____')\n",
    "            #Creating the features (tf-idf weights) for the processed text\n",
    "            texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "            tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                               min_df = 2, \n",
    "                                               max_df = .95)\n",
    "            X = tfidf_vectorizer.fit_transform(texts)     \n",
    "            y = df[category].values\n",
    "\n",
    "            if len(category) > 50:\n",
    "                 shorter = category[0:20]\n",
    "                 #save vectorizer:\n",
    "                 filename = '../../models/tf_idf/transformed_sectors/'+shorter+'_'+'vectorizer.sav'\n",
    "                 joblib.dump(tfidf_vectorizer, filename)    \n",
    "\n",
    "            else:\n",
    "                #save vectorizer:\n",
    "                filename = '../../models/tf_idf/transformed_sectors/'+category+'_'+'vectorizer.sav'\n",
    "                joblib.dump(tfidf_vectorizer, filename)    \n",
    "\n",
    "            #Dimenionality reduction. Only using the 100 best features er category\n",
    "            lsa = TruncatedSVD(n_components=100, \n",
    "                               n_iter=10, \n",
    "                               random_state=3)\n",
    "            X = lsa.fit_transform(X)\n",
    "\n",
    "            if len(category) > 50:\n",
    "                print('long')\n",
    "                shorter = category[0:20]\n",
    "                #save lsa model:\n",
    "                filename = '../../models/tf_idf/transformed_sectors/'+shorter+'_'+'lsa.sav'\n",
    "                joblib.dump(lsa, filename)\n",
    "            else:\n",
    "                #save vectorizer:\n",
    "                filename = '../../models/tf_idf/transformed_sectors/'+category+'_'+'lsa.sav'\n",
    "                joblib.dump(lsa, filename)  \n",
    "\n",
    "            #Train test split with stratified sampling for evaluation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, \n",
    "                                                                test_size = .3, \n",
    "                                                                shuffle = True, \n",
    "                                                                stratify = y, \n",
    "                                                                random_state = 3)\n",
    "\n",
    "            m.model_score_df(model_dict, category, 'transformed_sectors', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
