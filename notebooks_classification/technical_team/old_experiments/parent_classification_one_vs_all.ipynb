{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jonas\n",
      "[nltk_data]     Nothnagel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Jonas\n",
      "[nltk_data]     Nothnagel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('../..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import clean_dataset as clean\n",
    "import make_dataset as mk\n",
    "import vectorize_embed as em\n",
    "import tools as tools\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "'''features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import joblib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(603, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import data'''\n",
    "\n",
    "df = pd.read_json(os.path.abspath(os.path.join('../..', 'data/processed/encoded_labels'))+'/technical_team_all.json')  \n",
    "'''lowercase data and str type data'''\n",
    "df['all_text_clean_spacy'] = df['all_text_clean_spacy'].astype(str).apply(clean.basic)\n",
    "df['all_text_clean'] = df['all_text_clean'].astype(str)\n",
    "\n",
    "df.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'chemicals_and_waste_programme', 'climate_change_adaptation_programme',\n",
       "       'climate_forest_of_climate_change_mitigation',\n",
       "       'climate_strategies_and_policy_programme',\n",
       "       'ecosystems_and_biodiversity_programme',\n",
       "       'energy_program_of_climate_change_mitigation',\n",
       "       'oceans_and_water_programme', 'environmental_governance_programme',\n",
       "       'category_1', 'category_2', 'category_3', 'labels'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''remove small data points'''\n",
    "df_trunc = mk.truncate(df, 500, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Holding out 5 rows from the original dataframe for prediction at the end\n",
    "df_holdout = df_trunc.iloc[:5]\n",
    "\n",
    "df_trunc = df_trunc.iloc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df_trunc['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "   \n",
    "\n",
    "y = df_trunc['environmental_governance_programme'].values\n",
    "\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\dummy.py:131: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  warnings.warn(\"The default value of strategy will change from \"\n",
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Jonas\\Anaconda3\\envs\\nce_1\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stochastic Gradient Descent</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K Nearest Neighbor</td>\n",
       "      <td>0.988024</td>\n",
       "      <td>0.494012</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.496988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stochastic Gradient Descent balanceed</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.49697</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decsision Tree</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.49697</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gaussian Naive Bayes</td>\n",
       "      <td>0.982036</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.49697</td>\n",
       "      <td>0.495468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression balanced</td>\n",
       "      <td>0.958084</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.489297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              model_name accuracy_score precision_score  \\\n",
       "0                                  Dummy       0.988024        0.494012   \n",
       "2                    Logistic Regression       0.988024        0.494012   \n",
       "3            Stochastic Gradient Descent       0.988024        0.494012   \n",
       "5                          Random Forest       0.988024        0.494012   \n",
       "7                               AdaBoost       0.988024        0.494012   \n",
       "9                     K Nearest Neighbor       0.988024        0.494012   \n",
       "4  Stochastic Gradient Descent balanceed       0.982036        0.493976   \n",
       "6                         Decsision Tree       0.982036        0.493976   \n",
       "8                   Gaussian Naive Bayes       0.982036        0.493976   \n",
       "1           Logistic Regression balanced       0.958084        0.493827   \n",
       "\n",
       "  recall_score  f1_score  \n",
       "0          0.5  0.496988  \n",
       "2          0.5  0.496988  \n",
       "3          0.5  0.496988  \n",
       "5          0.5  0.496988  \n",
       "7          0.5  0.496988  \n",
       "9          0.5  0.496988  \n",
       "4      0.49697  0.495468  \n",
       "6      0.49697  0.495468  \n",
       "8      0.49697  0.495468  \n",
       "1     0.484848  0.489297  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preliminary model evaluation using default parameters\n",
    "\n",
    "#Creating a dict of the models\n",
    "model_dict = {'Dummy' : DummyClassifier(random_state=3),\n",
    "              'Logistic Regression balanced' : LogisticRegression(random_state = 3, class_weight = \"balanced\"),\n",
    "              'Logistic Regression' : LogisticRegression(random_state = 3),\n",
    "              'Stochastic Gradient Descent' : SGDClassifier(random_state=3, loss='log'),\n",
    "              'Stochastic Gradient Descent balanceed' : SGDClassifier(random_state=3, loss='log',class_weight = \"balanced\" ),\n",
    "              'Random Forest': RandomForestClassifier(random_state=3),\n",
    "              'Decsision Tree': DecisionTreeClassifier(random_state=3),\n",
    "              'AdaBoost': AdaBoostClassifier(random_state=3),\n",
    "              'Gaussian Naive Bayes': GaussianNB(),\n",
    "              'K Nearest Neighbor': KNeighborsClassifier()}\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True, \n",
    "                                                    stratify = y, \n",
    "                                                    random_state = 3)\n",
    "\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "model_score_df(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_log_classifier(dataframe, category):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(dataframe['all_text_clean'],\n",
    "                                                        dataframe[category].values,\n",
    "                                                        test_size = .3,\n",
    "                                                        random_state = 1,\n",
    "                                                        shuffle = True)\n",
    "    print('training size:', len(X_train))\n",
    "    print('test size:', len(X_test))\n",
    "    print('distribution of tagged projects:', dataframe[category].value_counts())\n",
    "    #if weighted == True:\n",
    "        #class_weights = tools.get_class_weights(y_train)\n",
    "        #print(class_weights)\n",
    "    #else: \n",
    "        #class_weights = None\n",
    "        \n",
    "\n",
    "    '''extract features using tfidf vecorization:'''\n",
    "    vectorizer = TfidfVectorizer(ngram_range = (1,2), min_df = 0.01, max_df = 0.95)\n",
    "    vect = vectorizer.fit(X_train)\n",
    "    X_train = vect.transform(X_train)\n",
    "    X_test = vect.transform(X_test)\n",
    "    \n",
    "    \"feature reduction\"\n",
    "    #lsa = TruncatedSVD(n_components=100, \n",
    "                   #n_iter=10, \n",
    "                   #random_state=3)\n",
    "\n",
    "    #X_train = lsa.fit_transform(X_train)\n",
    "    #X_test = lsa.fit_transform(X_test)    \n",
    "    \n",
    "    \n",
    "    # set pipeline\n",
    "    pipe = Pipeline([('classifier' , LogisticRegression())])\n",
    "\n",
    "    # Create param grid.\n",
    "    param_grid = [\n",
    "        {'classifier' : [LogisticRegression(class_weight = \"balanced\")],\n",
    "         'classifier__penalty' : ['l1', 'l2'],\n",
    "        'classifier__C' : np.logspace(-4, 4, 20),\n",
    "        'classifier__solver' : ['liblinear ','lbfgs']}\n",
    "    ]\n",
    "\n",
    "    # Create grid search object\n",
    "    clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1, scoring = 'accuracy')\n",
    "\n",
    "    # Fit on data\n",
    "    best_clf = clf.fit(X_train, y_train)\n",
    "    print('')\n",
    "    print('Training accuracy:', best_clf.score(X_train, y_train).round(3))\n",
    "    print('Test accuracy:', best_clf.score(X_test, y_test).round(3))\n",
    "    y_hat = best_clf.predict(X_test)\n",
    "    print('recall', recall_score(y_test, y_hat))\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, y_hat))    \n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_hat).ravel()\n",
    "    specificity = tn / (tn+fp)\n",
    "    print('specificity is:', specificity)\n",
    "\n",
    "    return best_clf, vectorizer, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 387\n",
      "test size: 167\n",
      "distribution of tagged projects: 0    515\n",
      "1     39\n",
      "Name: chemicals_and_waste_programme, dtype: int64\n",
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=-1)]: Done 360 tasks      | elapsed:    5.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.988\n",
      "recall 0.875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       151\n",
      "           1       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.99       167\n",
      "   macro avg       0.99      0.94      0.96       167\n",
      "weighted avg       0.99      0.99      0.99       167\n",
      "\n",
      "specificity is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:    5.8s finished\n"
     ]
    }
   ],
   "source": [
    "best_clf, vectorizer, y_train = binary_log_classifier(df_trunc, 'chemicals_and_waste_programme')\n",
    "\n",
    "# precision 0.33 on class 1: 33% of all items predicted as 1 are truly 1.\n",
    "# recall 0.6 on class 1: 60% of all true 1 are predicted as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
