{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jonas\n",
      "[nltk_data]     Nothnagel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Jonas\n",
      "[nltk_data]     Nothnagel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Jonas\n",
      "[nltk_data]     Nothnagel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Jonas\n",
      "[nltk_data]     Nothnagel\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import clean_dataset as clean\n",
    "import make_dataset as mk\n",
    "import vectorize_embed as em\n",
    "import tools as tools\n",
    "import models as m\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "'''features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import joblib\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import data'''\n",
    "df = pd.read_csv(os.path.abspath(os.path.join('..', 'data/processed/'))+'/taxonomy_final.csv')  \n",
    "df['all_text_clean_spacy'] = df['all_text_clean_spacy'].astype(str).apply(clean.basic)\n",
    "df['all_text_clean'] = df['all_text_clean'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = df.drop(columns=['PIMS_ID','all_text_clean', 'all_text_clean_spacy'])\n",
    "categories = cats.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: forests\n",
      "_____\n",
      "processing: conserve_areas\n",
      "_____\n",
      "processing: freshwaters\n",
      "_____\n",
      "processing: grasslands\n",
      "_____\n",
      "processing: marine\n",
      "_____\n",
      "processing: wetlands\n",
      "_____\n",
      "processing: human_altered_areas\n",
      "_____\n",
      "processing: coasts\n",
      "_____\n",
      "processing: coral_reefs\n",
      "_____\n",
      "processing: dryland_forests\n",
      "_____\n",
      "processing: indigenous_and_communities_conserved_areas_iccas\n",
      "_____\n",
      "processing: industrial_site\n",
      "_____\n",
      "processing: key_biodiversity_areas_kbas\n",
      "_____\n",
      "processing: marine_and_coastal_protected_areas\n",
      "_____\n",
      "processing: montane_forests\n",
      "_____\n",
      "processing: productive_landscapes_seascapes\n",
      "_____\n",
      "processing: rivers_and_river_basins\n",
      "_____\n",
      "processing: rural_areas\n",
      "_____\n",
      "processing: terrestrial_protected_areas\n",
      "_____\n",
      "processing: tropical_forests\n",
      "_____\n",
      "processing: urban_areas\n",
      "_____\n",
      "processing: large_marine_ecosystem\n",
      "_____\n",
      "processing: chemicals_and_waste_programme\n",
      "_____\n",
      "processing: climate_change_adaptation_programme\n",
      "_____\n",
      "processing: climate_forest_of_climate_change_mitigation\n",
      "_____\n",
      "processing: climate_strategies_and_policy_programme\n",
      "_____\n",
      "processing: ecosystems_and_biodiversity_programme\n",
      "_____\n",
      "processing: energy_program_of_climate_change_mitigation\n",
      "_____\n",
      "processing: oceans_and_water_programme\n",
      "_____\n",
      "processing: climate_information_and_early_warning_systems_ci_ews\n",
      "_____\n",
      "long\n",
      "climate_information_\n",
      "processing: cross_sectoral_climate_resilient_livelihoods\n",
      "_____\n",
      "processing: ecosystem_management_and_restoration\n",
      "_____\n",
      "processing: energy_access\n",
      "_____\n",
      "processing: energy_efficiency\n",
      "_____\n",
      "processing: fostering_food_security_and_resilient_agricultural_systems\n",
      "_____\n",
      "long\n",
      "fostering_food_secur\n",
      "processing: mainstreaming_biodiversity\n",
      "_____\n",
      "processing: mainstreaming_integrated_policy_and_planning_for_climate_resilient_sustainable_development\n",
      "_____\n",
      "long\n",
      "mainstreaming_integr\n",
      "processing: miscellaneous_energy_program\n",
      "_____\n",
      "processing: persistent_organic_pollutants\n",
      "_____\n",
      "processing: renewable_energy\n",
      "_____\n",
      "processing: strengthening_conservation_areas\n",
      "_____\n",
      "processing: chemical_waste_management\n",
      "_____\n",
      "processing: _access_and_benefit_sharing\n",
      "_____\n",
      "processing: _agrobiodiversity\n",
      "_____\n",
      "processing: _appliances\n",
      "_____\n",
      "processing: _biodiversity_financing\n",
      "_____\n",
      "processing: _buildings\n",
      "_____\n",
      "processing: _ecosystem_based_adaptation\n",
      "_____\n",
      "processing: _ecosystem_based_mitigation\n",
      "_____\n",
      "processing: _electricity_access\n",
      "_____\n",
      "processing: _resource_biomass\n",
      "_____\n",
      "processing: _resource_hydro\n",
      "_____\n",
      "processing: _resource_solar\n",
      "_____\n",
      "processing: _transport\n",
      "_____\n",
      "processing: _type_off_grid_mini_grids\n",
      "_____\n",
      "processing: _wildlife_conservation\n",
      "_____\n",
      "processing: capacity_building\n",
      "_____\n",
      "processing: enabling\n",
      "_____\n",
      "processing: finance_economy\n",
      "_____\n",
      "processing: food_and_agricultural_commodities\n",
      "_____\n",
      "processing: governance\n",
      "_____\n",
      "processing: law_regulation\n",
      "_____\n",
      "processing: management_operation\n",
      "_____\n",
      "processing: mitigation_adaptation\n",
      "_____\n",
      "processing: monitor_inventory\n",
      "_____\n",
      "processing: technology_innovation\n",
      "_____\n",
      "processing: awareness_raising\n",
      "_____\n",
      "processing: community_capacity_building\n",
      "_____\n",
      "processing: community_engagement\n",
      "_____\n",
      "processing: conserved_areas_protected_areas_management\n",
      "_____\n",
      "processing: demonstration_sites_pilot\n",
      "_____\n",
      "processing: ecosystem_and_ecosystem_services_conservation_restoration\n",
      "_____\n",
      "long\n",
      "ecosystem_and_ecosys\n",
      "processing: ecosystem_based_management\n",
      "_____\n",
      "processing: impact_assessment\n",
      "_____\n",
      "processing: institutional_capacity_building\n",
      "_____\n",
      "processing: institutional_framework\n",
      "_____\n",
      "processing: knowledge_data_management\n",
      "_____\n",
      "processing: laws_policy_plan_formulation\n",
      "_____\n",
      "processing: mainstream\n",
      "_____\n",
      "processing: new_other_financial_schemes_mechanism\n",
      "_____\n",
      "processing: participatory_governance_models\n",
      "_____\n",
      "processing: partnerships\n",
      "_____\n",
      "processing: sustainable_agriculture_practices_and_use_of_resources_tp_2_7_8_9\n",
      "_____\n",
      "long\n",
      "sustainable_agricult\n",
      "processing: sustainable_land_management\n",
      "_____\n",
      "processing: technical_capacity_building\n",
      "_____\n",
      "processing: waste_management\n",
      "_____\n",
      "processing: wildlife_and_habitat_conservation\n",
      "_____\n",
      "processing: data_quality\n",
      "_____\n",
      "processing: environmental_accounting\n",
      "_____\n",
      "processing: laws_enforcement_regulation\n",
      "_____\n",
      "processing: nature_finance\n",
      "_____\n",
      "processing: fiscal_planning\n",
      "_____\n",
      "processing: inter_sectoral_coordination\n",
      "_____\n",
      "processing: standards_labeling_guideline\n",
      "_____\n",
      "processing: energy_finance\n",
      "_____\n",
      "processing: people_pathway\n",
      "_____\n",
      "processing: sci_tech_pathway\n",
      "_____\n",
      "processing: systems_pathway\n",
      "_____\n",
      "processing: hazard_control_mitigation\n",
      "_____\n",
      "processing: improve_resilience\n",
      "_____\n",
      "processing: reduce_exposure\n",
      "_____\n",
      "processing: _metals_and_mining\n",
      "_____\n",
      "processing: agriculture\n",
      "_____\n",
      "processing: aquaculture\n",
      "_____\n",
      "processing: energy\n",
      "_____\n",
      "processing: fisheries\n",
      "_____\n",
      "processing: forestry_and_other_land_use\n",
      "_____\n",
      "processing: livestock\n",
      "_____\n",
      "processing: materials_and_manufacturing\n",
      "_____\n",
      "processing: other_sectors\n",
      "_____\n",
      "processing: tourism\n",
      "_____\n",
      "processing: transportation\n",
      "_____\n",
      "processing: capacity_development_technical_assistance\n",
      "_____\n",
      "processing: convening_partnerships_knowledge_sharing\n",
      "_____\n",
      "processing: data_collection_and_analysis\n",
      "_____\n",
      "processing: direct_support_service_delivery\n",
      "_____\n",
      "processing: innovative_approaches\n",
      "_____\n",
      "processing: institutional_mechanism_and_system_building\n",
      "_____\n",
      "processing: normative_support\n",
      "_____\n",
      "processing: optimising_financing\n",
      "_____\n",
      "processing: policy_advice\n",
      "_____\n",
      "processing: convention_on_biological_diversity_cbd\n",
      "_____\n",
      "processing: national_action_plan\n",
      "_____\n",
      "processing: national_adaptation_plan_nap\n",
      "_____\n",
      "processing: national_biodiversity_strategies_and_action_plans_nbsaps\n",
      "_____\n",
      "long\n",
      "national_biodiversit\n",
      "processing: national_communications\n",
      "_____\n",
      "processing: national_determined_contributions_ndcs\n",
      "_____\n",
      "processing: other_global_conventions\n",
      "_____\n",
      "processing: stockholm_convention_pops\n",
      "_____\n",
      "processing: strategic_action_programme\n",
      "_____\n",
      "processing: united_nations_convention_to_combat_desertification_unccd\n",
      "_____\n",
      "long\n",
      "united_nations_conve\n",
      "processing: united_nations_framework_convention_on_climate_change_unfccc\n",
      "_____\n",
      "long\n",
      "united_nations_frame\n",
      "processing: awareness_raising_on_gender\n",
      "_____\n",
      "processing: gender_responsive_policies\n",
      "_____\n",
      "processing: livelihoods_for_women\n",
      "_____\n",
      "processing: women_decision_making\n",
      "_____\n",
      "processing: women_farmers\n",
      "_____\n",
      "processing: women_s_access_to_and_control_over_resources\n",
      "_____\n",
      "processing: women_s_cooperatives_and_groups\n",
      "_____\n",
      "processing: food_and_agricultural_commodities_strategy\n",
      "_____\n",
      "processing: health\n",
      "_____\n",
      "processing: multi_stakeholder_collaboration\n",
      "_____\n",
      "processing: nature_based_solution\n",
      "_____\n",
      "processing: poverty_reduction\n",
      "_____\n",
      "processing: public_private_partnership\n",
      "_____\n",
      "processing: sids\n",
      "_____\n",
      "processing: structural_system_transformation\n",
      "_____\n",
      "processing: indigenous_peoples\n",
      "_____\n",
      "processing: local_community_csos\n",
      "_____\n",
      "processing: private_sector\n",
      "_____\n",
      "processing: smallholder_farmers\n",
      "_____\n",
      "processing: women\n",
      "_____\n",
      "processing: youth_children\n",
      "_____\n",
      "processing: capital_providers\n",
      "_____\n",
      "processing: financial_intermediaries_and_market_facilitators\n",
      "_____\n",
      "processing: individuals_entrepreneurs\n",
      "_____\n",
      "processing: large_corporations\n",
      "_____\n",
      "processing: small_and_medium_sized_enterprises\n",
      "_____\n"
     ]
    }
   ],
   "source": [
    "# iterate over categories and save best models:\n",
    "    #Creating a dict of the models\n",
    "model_dict = {\n",
    "              'LR_balanced' : LogisticRegression(random_state = 3, class_weight = \"balanced\"),\n",
    "              'LR' : LogisticRegression(random_state = 3),\n",
    "              'SDG' : SGDClassifier(random_state=3, loss='log'),\n",
    "              'SDG_balanceed' : SGDClassifier(random_state=3, loss='log',class_weight = \"balanced\" ),\n",
    "              'RF': RandomForestClassifier(random_state=3),\n",
    "              'Decsision_Tree': DecisionTreeClassifier(random_state=3),\n",
    "              'AdaBoost': AdaBoostClassifier(random_state=3),\n",
    "              'GNB': GaussianNB(),\n",
    "              'KNB': KNeighborsClassifier()}\n",
    "    \n",
    "for category in categories: \n",
    "    if category != \"no tag\":\n",
    "        if df[category].sum(axis=0) > 20:\n",
    "            \n",
    "            print('processing:', category)\n",
    "            print('_____')\n",
    "            #Creating the features (tf-idf weights) for the processed text\n",
    "            texts = df['all_text_clean_spacy'].astype('str')\n",
    "\n",
    "            tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                               min_df = 2, \n",
    "                                               max_df = .95)\n",
    "            X = tfidf_vectorizer.fit_transform(texts)     \n",
    "            y = df[category].values\n",
    "\n",
    "            if len(category) > 50:\n",
    "                 shorter = category[0:20]\n",
    "                 #save vectorizer:\n",
    "                 filename = '../models/tf_idf/tf_idf_lsa/'+shorter+'_'+'vectorizer.sav'\n",
    "                 joblib.dump(tfidf_vectorizer, filename)    \n",
    "\n",
    "            else:\n",
    "                #save vectorizer:\n",
    "                filename = '../models/tf_idf/tf_idf_lsa/'+category+'_'+'vectorizer.sav'\n",
    "                joblib.dump(tfidf_vectorizer, filename)    \n",
    "\n",
    "            #Dimenionality reduction. Only using the 100 best features er category\n",
    "            lsa = TruncatedSVD(n_components=100, \n",
    "                               n_iter=10, \n",
    "                               random_state=3)\n",
    "            X = lsa.fit_transform(X)\n",
    "\n",
    "            if len(category) > 50:\n",
    "                print('long')\n",
    "                shorter = category[0:20]\n",
    "                #save lsa model:\n",
    "                filename = '../models/tf_idf/tf_idf_lsa/'+shorter+'_'+'lsa.sav'\n",
    "                joblib.dump(lsa, filename)\n",
    "            else:\n",
    "                #save vectorizer:\n",
    "                filename = '../models/tf_idf/tf_idf_lsa/'+category+'_'+'lsa.sav'\n",
    "                joblib.dump(lsa, filename)  \n",
    "\n",
    "            #Train test split with stratified sampling for evaluation\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                                y, \n",
    "                                                                test_size = .3, \n",
    "                                                                shuffle = True, \n",
    "                                                                stratify = y, \n",
    "                                                                random_state = 3)\n",
    "\n",
    "            m.model_score_df_all(model_dict, category, 'tf_idf_lsa', X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
