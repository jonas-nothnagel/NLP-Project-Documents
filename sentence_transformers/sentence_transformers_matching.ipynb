{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "banner-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import pickle5 as pickle\n",
    "from inspect import getsourcefile\n",
    "import os.path as path, sys\n",
    "current_dir = path.dirname(path.abspath(getsourcefile(lambda:0)))\n",
    "sys.path.insert(0, current_dir[:current_dir.rfind(path.sep)])\n",
    "\n",
    "import pandas as pd\n",
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interesting-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "df_targets = pd.read_csv('../data/processed/taxonomy_final_targets.csv')\n",
    "df_columns = df_targets.drop(columns=['PIMS_ID', 'all_text', 'all_text_clean', 'all_text_clean_spacy',  'hyperlink',\n",
    " 'title',\n",
    " 'leading_country',\n",
    " 'grant_amount',\n",
    " 'country_code',\n",
    " 'lon',\n",
    " 'lat'])\n",
    "    \n",
    "to_match_targets = df_columns.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experienced-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(to_match_targets)):\n",
    "    to_match_targets[i] = to_match_targets[i].replace('_', ' ')\n",
    "for i in range(len(to_match_targets)):\n",
    "    to_match_targets[i] = to_match_targets[i].lstrip()\n",
    "    \n",
    "original  = df_columns.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-composition",
   "metadata": {},
   "source": [
    "Download and compare two different models as a start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggregate-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "danish-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "packed-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute embeddings\n",
    "corpus_embeddings = embedder.encode(to_match_targets, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "assigned-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corpus_embeddings_roberta, open(\"../data/processed/corpus_embeddings_paraphrase_distilbert.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = input()\n",
    "query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "print('___________________________')\n",
    "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=20)\n",
    "hits = hits[0] #Get the hits for the first query\n",
    "matches = []\n",
    "for hit in hits:\n",
    "    matches.append(original[hit['corpus_id']])\n",
    "    print(original[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute embeddings\n",
    "corpus_embeddings_roberta = model.encode(to_match_targets, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(corpus_embeddings_roberta, open(\"../data/processed/corpus_embeddings_roberta.pkl\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expired-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load embeddings\n",
    "corpus_embeddings_roberta = pickle.load(open(\"../data/processed/corpus_embeddings_roberta.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "assisted-surrey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plastic\n",
      "___________________________\n",
      "plastic (Score: 1.0000)\n",
      "oceans_and_water_programme (Score: 0.5029)\n",
      "seas (Score: 0.4624)\n",
      "peatlands (Score: 0.4517)\n",
      "lakes (Score: 0.4082)\n",
      "large_marine_ecosystem (Score: 0.3956)\n",
      "wastewater_management (Score: 0.3915)\n",
      "rivers_and_river_basins (Score: 0.3850)\n",
      "marine_spatial_planning (Score: 0.3817)\n",
      "mainstreaming_biodiversity (Score: 0.3809)\n",
      "waste_picker (Score: 0.3756)\n",
      "marine (Score: 0.3721)\n",
      "coasts (Score: 0.3720)\n",
      "portfolio_learning (Score: 0.3678)\n",
      "water_quality_quantity (Score: 0.3676)\n",
      "waste_management (Score: 0.3587)\n",
      "specially_protected_areas_spas (Score: 0.3567)\n",
      "_type_thermal (Score: 0.3450)\n",
      "swamps (Score: 0.3380)\n",
      "blue_economy (Score: 0.3375)\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "query_embedding = model.encode(query, convert_to_tensor=True)\n",
    "print('___________________________')\n",
    "hits = util.semantic_search(query_embedding, corpus_embeddings_roberta, top_k=20)\n",
    "hits = hits[0] #Get the hits for the first query\n",
    "matches = []\n",
    "for hit in hits:\n",
    "    matches.append(original[hit['corpus_id']])\n",
    "    print(original[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-eight",
   "metadata": {},
   "source": [
    "Note: Roberta model seems to work better and gives better results (in my opinion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-shape",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
