{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basics'''\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "\n",
    "'''Plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "'''features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "from sklearn_hierarchical_classification.constants import ROOT\n",
    "from sklearn_hierarchical_classification.metrics import h_fbeta_score, multi_labeled\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and holdout data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'forest', 'tropical_forests', 'temperate_forests', 'dryland_forests',\n",
       "       'montane_forests', 'intact_forests', 'boreal_forests_taiga_forests'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Forest.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tropical_forests</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>temperate_forests</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dryland_forests</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>montane_forests</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intact_forests</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>boreal_forests_taiga_forests</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       category  number_of_inputs\n",
       "0              tropical_forests                38\n",
       "1             temperate_forests                 4\n",
       "2               dryland_forests                14\n",
       "3               montane_forests                17\n",
       "4                intact_forests                 7\n",
       "5  boreal_forests_taiga_forests                 1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'forest'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats.plot(x='category', y='number_of_inputs', kind='bar', legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of comments per category\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('category', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many comments have multi labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of categories')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowsums = df.iloc[:,4:].sum(axis=1)\n",
    "x=rowsums.value_counts()\n",
    "#plot\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of categories', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distribution of the number of words in input texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1de9409048>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = df.all_text_clean.str.len()\n",
    "lens.hist(bins = np.arange(0,5000,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holding out 5 rows from the original dataframe for prediction at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_holdout = df.iloc[:5]\n",
    "\n",
    "df = df.iloc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'forest', 'tropical_forests', 'temperate_forests', 'dryland_forests',\n",
       "       'montane_forests', 'intact_forests', 'boreal_forests_taiga_forests'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['tropical_forests', 'temperate_forests', 'dryland_forests',\n",
    "       'montane_forests', 'intact_forests', 'boreal_forests_taiga_forests']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multiple ML models / OneVsRest multi-label strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "#print (tabulate(rows, header, tablefmt='html'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                    </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>tropical_forests            </td><td style=\"text-align: right;\">       38</td><td>K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " Random Forest              </td><td>0.696969696969697    \n",
    " 0.6363636363636364    \n",
    " 0.6363636363636364    \n",
    " 0.6666666666666666    \n",
    " 0.48484848484848486    \n",
    " 0.6363636363636364                 </td><td>0.6930147058823529   \n",
    " 0.5833333333333333   \n",
    " 0.5833333333333333   \n",
    " 0.6666666666666666   \n",
    " 0.4027777777777778   \n",
    " 0.3181818181818182                  </td><td>0.7083333333333333    \n",
    " 0.5535714285714286    \n",
    " 0.5535714285714286    \n",
    " 0.5595238095238095    \n",
    " 0.41666666666666663    \n",
    " 0.5000000000000009               </td><td>0.6898496240601504    \n",
    " 0.5416666666666666    \n",
    " 0.5416666666666666    \n",
    " 0.5254901960784314    \n",
    " 0.40634920634920635    \n",
    " 0.3888888888888889           </td></tr>\n",
    "<tr><td>temperate_forests           </td><td style=\"text-align: right;\">        4</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.9090909090909091                 </td><td>0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.45454545454545453                  </td><td>0.5000000000000009    \n",
    " 0.5000000000000009\n",
    " 0.5000000000000009    \n",
    " 0.5000000000000009    \n",
    " 0.5000000000000009    \n",
    " 0.5000000000000009               </td><td>0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616           </td></tr>\n",
    "<tr><td>dryland_forests             </td><td style=\"text-align: right;\">       14</td><td>Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree              </td><td>0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.8787878787878788    \n",
    " 0.8787878787878788    \n",
    " 0.8787878787878788    \n",
    " 0.7878787878787878                 </td><td>0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.4531250000000009\n",
    " 0.4531250000000009\n",
    " 0.4531250000000009\n",
    " 0.4482758620689655                  </td><td>0.5000000000000009    \n",
    " 0.5000000000000009    \n",
    " 0.48333333333333334    \n",
    " 0.48333333333333334    \n",
    " 0.48333333333333334    \n",
    " 0.43333333333333335               </td><td>0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.46774193548387094    \n",
    " 0.46774193548387094    \n",
    " 0.46774193548387094    \n",
    " 0.44067796610169496           </td></tr>\n",
    "<tr><td>montane_forests             </td><td style=\"text-align: right;\">       17</td><td>Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.9393939393939394    \n",
    " 0.9393939393939394    \n",
    " 0.9090909090909091    \n",
    " 0.8787878787878788    \n",
    " 0.8181818181818182    \n",
    " 0.8787878787878788                 </td><td>0.968750000000\n",
    " 0.9687500000000009\n",
    " 0.717741935483871   \n",
    " 0.6333333333333333   \n",
    " 0.5642857142857143   \n",
    " 0.4531250000000009        </td><td>0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.6500000000000009    \n",
    " 0.6333333333333333    \n",
    " 0.6000000000000009    \n",
    " 0.48333333333333334               </td><td>0.7338709677419355    \n",
    " 0.7338709677419355    \n",
    " 0.6754098360655738    \n",
    " 0.6333333333333333    \n",
    " 0.5732758620689655    \n",
    " 0.46774193548387094           </td></tr>\n",
    "<tr><td>intact_forests              </td><td style=\"text-align: right;\">        7</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.9090909090909091    \n",
    " 0.8787878787878788    \n",
    " 0.8787878787878788                 </td><td>0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.45454545454545453   \n",
    " 0.4531250000000009\n",
    " 0.4531250000000009        </td><td>0.5000000000000009    \n",
    " 0.5000000000000009    \n",
    " 0.5000000000000009    \n",
    " 0.5000000000000009    \n",
    " 0.48333333333333334    \n",
    " 0.48333333333333334               </td><td>0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616    \n",
    " 0.46774193548387094    \n",
    " 0.46774193548387094           </td></tr>\n",
    "<tr><td>boreal_forests_taiga_forests</td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 0.9393939393939394                 </td><td>1.000000000000000   \n",
    " 1.000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 0.5000000000000009                 </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.4696969696969697               </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.4843750000000000           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tundra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'tundra', 'alpine_tundra'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Tundra.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpine_tundra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  number_of_inputs\n",
       "0  alpine_tundra                 1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'tundra'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conserved_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'conserved_areas', '_indigenous_protected_and_conserved_areas_ipcas_x',\n",
       "       '_indigenous_protected_and_conserved_areas_ipcas_y',\n",
       "       'marine_and_coastal_protected_areas', 'terrestrial_protected_areas',\n",
       "       'indigenous_and_communities_conserved_areas_icca',\n",
       "       'transboundary_conservation_areas', 'productive_landscapes_seascapes',\n",
       "       'key_biodiversity_areas_kba',\n",
       "       '_important_bird_and_biodiversity_areas_ibas',\n",
       "       'specially_protected_areas_spas',\n",
       "       '_indigenous_protected_and_conserved_areas_ipcas',\n",
       "       'protected_areas_network',\n",
       "       'oecm_other_effective_area_based_conservation_measures',\n",
       "       'locally_managed_marine_areas'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Conserved_Areas.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_indigenous_protected_and_conserved_areas_ipcas_x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_indigenous_protected_and_conserved_areas_ipcas_y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marine_and_coastal_protected_areas</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>terrestrial_protected_areas</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigenous_and_communities_conserved_areas_icca</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transboundary_conservation_areas</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>productive_landscapes_seascapes</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key_biodiversity_areas_kba</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_important_bird_and_biodiversity_areas_ibas</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>specially_protected_areas_spas</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_indigenous_protected_and_conserved_areas_ipcas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>protected_areas_network</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oecm_other_effective_area_based_conservation_m...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>locally_managed_marine_areas</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             category  number_of_inputs\n",
       "0   _indigenous_protected_and_conserved_areas_ipcas_x                 2\n",
       "1   _indigenous_protected_and_conserved_areas_ipcas_y                 1\n",
       "2                  marine_and_coastal_protected_areas                48\n",
       "3                         terrestrial_protected_areas                76\n",
       "4     indigenous_and_communities_conserved_areas_icca                23\n",
       "5                    transboundary_conservation_areas                12\n",
       "6                     productive_landscapes_seascapes                56\n",
       "7                          key_biodiversity_areas_kba                51\n",
       "8         _important_bird_and_biodiversity_areas_ibas                12\n",
       "9                      specially_protected_areas_spas                14\n",
       "10    _indigenous_protected_and_conserved_areas_ipcas                 0\n",
       "11                            protected_areas_network                 7\n",
       "12  oecm_other_effective_area_based_conservation_m...                18\n",
       "13                       locally_managed_marine_areas                15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'conserved_areas'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['_indigenous_protected_and_conserved_areas_ipcas_x',\n",
    "       '_indigenous_protected_and_conserved_areas_ipcas_y',\n",
    "       'marine_and_coastal_protected_areas', 'terrestrial_protected_areas',\n",
    "       'indigenous_and_communities_conserved_areas_icca',\n",
    "       'transboundary_conservation_areas', 'productive_landscapes_seascapes',\n",
    "       'key_biodiversity_areas_kba',\n",
    "       '_important_bird_and_biodiversity_areas_ibas',\n",
    "       'specially_protected_areas_spas',\n",
    "       '_indigenous_protected_and_conserved_areas_ipcas',\n",
    "       'protected_areas_network',\n",
    "       'oecm_other_effective_area_based_conservation_measures',\n",
    "       'locally_managed_marine_areas']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                                             </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>_indigenous_protected_and_conserved_areas_ipcas_x    </td><td style=\"text-align: right;\">        2</td><td>Random Forest    <br>\n",
    " Decsision Tree   <br> \n",
    " Gaussian Naive Bayes <br>   \n",
    " K Nearest Neighbor <br>   \n",
    " Stochastic Gradient Descent  <br>  \n",
    " AdaBoost              </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174                 </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5   <br>\n",
    " 0.5       <br>           </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4891304347826087    \n",
    " 0.4891304347826087               </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945           </td></tr>\n",
    "<tr><td>_indigenous_protected_and_conserved_areas_ipcas_y    </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0                  </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0           </td></tr>\n",
    "<tr><td>marine_and_coastal_protected_areas                   </td><td style=\"text-align: right;\">       48</td><td>Random Forest    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.8913043478260869    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8478260869565217    \n",
    " 0.8043478260869565    \n",
    " 0.782608695652174                 </td><td>0.9418604651162791   \n",
    " 0.7083333333333333   \n",
    " 0.7083333333333333   \n",
    " 0.7390243902439024   \n",
    " 0.6681681681681682   \n",
    " 0.5916666666666667                  </td><td>0.6875    \n",
    " 0.7467105263157895    \n",
    " 0.7467105263157895    \n",
    " 0.6611842105263157    \n",
    " 0.6842105263157895    \n",
    " 0.5723684210526316               </td><td>0.7418630751964086    \n",
    " 0.7237237237237237    \n",
    " 0.7237237237237237    \n",
    " 0.6864654333008764    \n",
    " 0.6752941176470588    \n",
    " 0.5787545787545788           </td></tr>\n",
    "<tr><td>terrestrial_protected_areas                          </td><td style=\"text-align: right;\">       76</td><td>K Nearest Neighbor    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent              </td><td>0.6521739130434783    \n",
    " 0.6521739130434783    \n",
    " 0.6304347826086957    \n",
    " 0.6086956521739131    \n",
    " 0.5652173913043478    \n",
    " 0.5217391304347826                 </td><td>0.6519230769230769   \n",
    " 0.6646825396825397   \n",
    " 0.6304347826086957   \n",
    " 0.6383928571428572   \n",
    " 0.5791666666666666   \n",
    " 0.5625                  </td><td>0.6496212121212122    \n",
    " 0.6571969696969697    \n",
    " 0.6306818181818181    \n",
    " 0.6174242424242424    \n",
    " 0.571969696969697    \n",
    " 0.5359848484848485               </td><td>0.6495238095238096    \n",
    " 0.6495238095238095    \n",
    " 0.630260047281324    \n",
    " 0.5964912280701754    \n",
    " 0.5576923076923077    \n",
    " 0.47291666666666665           </td></tr>\n",
    "<tr><td>indigenous_and_communities_conserved_areas_icca      </td><td style=\"text-align: right;\">       23</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.782608695652174    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8043478260869565    \n",
    " 0.8043478260869565    \n",
    " 0.782608695652174                 </td><td>0.5916666666666667   \n",
    " 0.6704545454545454   \n",
    " 0.41304347826086957   \n",
    " 0.4111111111111111   \n",
    " 0.4111111111111111   \n",
    " 0.4090909090909091                  </td><td>0.5723684210526316    \n",
    " 0.549342105263158    \n",
    " 0.5    \n",
    " 0.4868421052631579    \n",
    " 0.4868421052631579    \n",
    " 0.47368421052631576               </td><td>0.5787545787545788    \n",
    " 0.551219512195122    \n",
    " 0.45238095238095233    \n",
    " 0.4457831325301205    \n",
    " 0.4457831325301205    \n",
    " 0.43902439024390244           </td></tr>\n",
    "<tr><td>transboundary_conservation_areas                     </td><td style=\"text-align: right;\">       12</td><td>Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost              </td><td>0.9782608695652174    \n",
    " 0.8913043478260869    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348                 </td><td>0.75   <br>\n",
    " 0.5833333333333334   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4888888888888889   \n",
    " 0.4888888888888889                  </td><td>0.9888888888888889    \n",
    " 0.9444444444444444<br>    \n",
    " 0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889               </td><td>0.8277153558052435    \n",
    " 0.6134453781512605    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889           </td></tr>\n",
    "<tr><td>productive_landscapes_seascapes                      </td><td style=\"text-align: right;\">       56</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Random Forest              </td><td>0.717391304347826    \n",
    " 0.6956521739130435    \n",
    " 0.6521739130434783    \n",
    " 0.717391304347826    \n",
    " 0.5869565217391305    \n",
    " 0.6956521739130435                 </td><td>0.6470588235294117   \n",
    " 0.6247086247086246   \n",
    " 0.6024340770791075   \n",
    " 0.631578947368421   \n",
    " 0.5229166666666667   \n",
    " 0.35555555555555557                  </td><td>0.6398601398601399    \n",
    " 0.6247086247086246    \n",
    " 0.6177156177156178    \n",
    " 0.5932400932400932    \n",
    " 0.5256410256410257    \n",
    " 0.48484848484848486               </td><td>0.6429850746268657    \n",
    " 0.6247086247086246    \n",
    " 0.6043010752688172    \n",
    " 0.5989268947015426    \n",
    " 0.5216201423097975    \n",
    " 0.41025641025641024           </td></tr>\n",
    "<tr><td>key_biodiversity_areas_kba                           </td><td style=\"text-align: right;\">       51</td><td>AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor              </td><td>0.6956521739130435    \n",
    " 0.7391304347826086    \n",
    " 0.6304347826086957    \n",
    " 0.6739130434782609    \n",
    " 0.7391304347826086    \n",
    " 0.6086956521739131                 </td><td>0.6490872210953347   \n",
    " 0.6696696696696697   \n",
    " 0.6038461538461539   \n",
    " 0.5906862745098039   \n",
    " 0.8666666666666667   \n",
    " 0.4935064935064935                  </td><td>0.6713286713286714    \n",
    " 0.6317016317016317    \n",
    " 0.6258741258741258    \n",
    " 0.5862470862470862    \n",
    " 0.5384615384615384    \n",
    " 0.4941724941724942               </td><td>0.6537634408602151    \n",
    " 0.6415584415584416    \n",
    " 0.5983564458140729    \n",
    " 0.5880597014925373    \n",
    " 0.49450549450549447    \n",
    " 0.49264705882352944           </td></tr>\n",
    "<tr><td>_important_bird_and_biodiversity_areas_ibas          </td><td style=\"text-align: right;\">       12</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9565217391304348                 </td><td>0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4888888888888889                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4888888888888889               </td><td>0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4888888888888889           </td></tr>\n",
    "<tr><td>specially_protected_areas_spas                       </td><td style=\"text-align: right;\">       14</td><td>Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree              </td><td>0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9347826086956522    \n",
    " 0.8695652173913043                 </td><td>0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4777777777777778   \n",
    " 0.47619047619047616                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.48863636363636365    \n",
    " 0.45454545454545453               </td><td>0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4831460674157304    \n",
    " 0.46511627906976744           </td></tr>\n",
    "<tr><td>_indigenous_protected_and_conserved_areas_ipcas      </td><td style=\"text-align: right;\">        0</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0 <br>   \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>   </td></tr>\n",
    "<tr><td>protected_areas_network                              </td><td style=\"text-align: right;\">        7</td><td>Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree              </td><td>0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9565217391304348    \n",
    " 0.9347826086956522                 </td><td>0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4888888888888889   \n",
    " 0.48863636363636365                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4888888888888889    \n",
    " 0.4777777777777778               </td><td>0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4888888888888889    \n",
    " 0.4831460674157304           </td></tr>\n",
    "<tr><td>oecm_other_effective_area_based_conservation_measures</td><td style=\"text-align: right;\">       18</td><td>Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree              </td><td>0.9130434782608695    \n",
    " 0.9130434782608695    \n",
    " 0.8913043478260869    \n",
    " 0.8913043478260869    \n",
    " 0.8260869565217391    \n",
    " 0.8043478260869565                 </td><td>0.45652173913043476   \n",
    " 0.45652173913043476   \n",
    " 0.45555555555555555   \n",
    " 0.45555555555555555   \n",
    " 0.4523809523809524   \n",
    " 0.45121951219512196                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.4880952380952381    \n",
    " 0.4880952380952381    \n",
    " 0.4523809523809524    \n",
    " 0.44047619047619047               </td><td>0.47727272727272724    \n",
    " 0.47727272727272724    \n",
    " 0.47126436781609193    \n",
    " 0.47126436781609193    \n",
    " 0.4523809523809524    \n",
    " 0.44578313253012053           </td></tr>\n",
    "<tr><td>locally_managed_marine_areas                         </td><td style=\"text-align: right;\">       15</td><td>AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.8695652173913043                 </td><td>0.75   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4878048780487805                  </td><td>0.9888888888888889    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4444444444444444               </td><td>0.8277153558052435    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.46511627906976744           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freshwater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'freshwater', 'rivers_and_river_basins', 'lakes', 'aquifers',\n",
       "       'estuaries'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Freshwater.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rivers_and_river_basins</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lakes</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aquifers</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estuaries</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  category  number_of_inputs\n",
       "0  rivers_and_river_basins                32\n",
       "1                    lakes                 8\n",
       "2                 aquifers                 6\n",
       "3                estuaries                 2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'freshwater'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['rivers_and_river_basins', 'lakes', 'aquifers','estuaries']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category               </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>rivers_and_river_basins</td><td style=\"text-align: right;\">       32</td><td>Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent              </td><td>0.6111111111111112    \n",
    " 0.6111111111111112    \n",
    " 0.5555555555555556    \n",
    " 0.5555555555555556    \n",
    " 0.5555555555555556    \n",
    " 0.5555555555555556                 </td><td>0.6250000000000000   \n",
    " 0.6250000000000000   \n",
    " 0.5555555555555556   \n",
    " 0.5584415584415584   \n",
    " 0.5692307692307692   \n",
    " 0.6000000000000000                  </td><td>0.6111111111111112    \n",
    " 0.6111111111111112    \n",
    " 0.5555555555555556    \n",
    " 0.5555555555555556    \n",
    " 0.5555555555555556    \n",
    " 0.5555555555555556               </td><td>0.600000000000000    \n",
    " 0.6000000000000000   \n",
    " 0.5555555555555556    \n",
    " 0.5500000000000000    \n",
    " 0.5324675324675324    \n",
    " 0.5000000000000000           </td></tr>\n",
    "<tr><td>lakes                  </td><td style=\"text-align: right;\">        8</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.8333333333333334    \n",
    " 0.8888888888888888    \n",
    " 0.8888888888888888    \n",
    " 0.8888888888888888    \n",
    " 0.8333333333333334    \n",
    " 0.8333333333333334                 </td><td>0.6333333333333333   \n",
    " 0.4444444444444444   \n",
    " 0.4444444444444444   \n",
    " 0.4444444444444444   \n",
    " 0.4411764705882353   \n",
    " 0.4411764705882353                  </td><td>0.68750000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.4687500000000000    \n",
    " 0.4687500000000000               </td><td>0.6516129032258065    \n",
    " 0.47058823529411764    \n",
    " 0.47058823529411764    \n",
    " 0.47058823529411764    \n",
    " 0.45454545454545453    \n",
    " 0.45454545454545453           </td></tr>\n",
    "<tr><td>aquifers               </td><td style=\"text-align: right;\">        6</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.8888888888888888    \n",
    " 0.8888888888888888    \n",
    " 0.8888888888888888    \n",
    " 0.8888888888888888    \n",
    " 0.8888888888888888    \n",
    " 0.7777777777777778                 </td><td>0.4444444444444444   \n",
    " 0.4444444444444444   \n",
    " 0.4444444444444444   \n",
    " 0.4444444444444444   \n",
    " 0.4444444444444444   \n",
    " 0.4375000000000000                  </td><td>0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.4375000000000000               </td><td>0.47058823529411764    \n",
    " 0.47058823529411764    \n",
    " 0.47058823529411764    \n",
    " 0.47058823529411764    \n",
    " 0.47058823529411764    \n",
    " 0.4375000000000000           </td></tr>\n",
    "<tr><td>estuaries              </td><td style=\"text-align: right;\">        2</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>1.0000000000000000    \n",
    " 1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 1.000000000000000    \n",
    " 0.9444444444444444                 </td><td>1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 0.5000000000000000                  </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.4722222222222222               </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.4857142857142857           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grassland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'grassland', 'grazing_land', 'tropical_grassland',\n",
       "       'temperate_grassland', 'savanna', 'steppes', 'drylands'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Grassland.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'grassland'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['grazing_land', 'tropical_grassland',\n",
    "       'temperate_grassland', 'savanna', 'steppes', 'drylands']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category           </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>grazing_land       </td><td style=\"text-align: right;\">       27</td><td>AdaBoost    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent              </td><td>0.8666666666666667    \n",
    " 0.8000000000000000    \n",
    " 0.6666666666666666    \n",
    " 0.6000000000000000    \n",
    " 0.6000000000000000    \n",
    " 0.5333333333333333                 </td><td>0.8750000000000000   \n",
    " 0.8333333333333333   \n",
    " 0.6666666666666666   \n",
    " 0.6071428571428572   \n",
    " 0.6071428571428572   \n",
    " 0.5000000000000000                  </td><td>0.8888888888888888    \n",
    " 0.8333333333333333    \n",
    " 0.611111111111111    \n",
    " 0.6111111111111112    \n",
    " 0.6111111111111112    \n",
    " 0.5000000000000000               </td><td>0.8660714285714286    \n",
    " 0.8000000000000000    \n",
    " 0.6031746031746033    \n",
    " 0.5982142857142858    \n",
    " 0.5982142857142858    \n",
    " 0.4976076555023923           </td></tr>\n",
    "<tr><td>tropical_grassland </td><td style=\"text-align: right;\">        9</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor              </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.9333333333333333    \n",
    " 0.9333333333333333                 </td><td>1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 0.8750000000000000   \n",
    " 0.8750000000000000                  </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.9583333333333333    \n",
    " 0.9583333333333333               </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.9068322981366459    \n",
    " 0.9068322981366459           </td></tr>\n",
    "<tr><td>temperate_grassland</td><td style=\"text-align: right;\">       10</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.9333333333333333    \n",
    " 0.9333333333333333    \n",
    " 0.9333333333333333    \n",
    " 0.8666666666666667    \n",
    " 0.8666666666666667    \n",
    " 0.7333333333333333                 </td><td>0.9583333333333333   \n",
    " 0.9583333333333333   \n",
    " 0.9583333333333333   \n",
    " 0.8295454545454546   \n",
    " 0.8295454545454546   \n",
    " 0.6590909090909092                  </td><td>0.8750000000000000    \n",
    " 0.8750000000000000    \n",
    " 0.8750000000000000    \n",
    " 0.8295454545454546    \n",
    " 0.8295454545454546    \n",
    " 0.6590909090909092               </td><td>0.9068322981366459    \n",
    " 0.9068322981366459    \n",
    " 0.9068322981366459    \n",
    " 0.8295454545454546    \n",
    " 0.8295454545454546    \n",
    " 0.6590909090909092           </td></tr>\n",
    "<tr><td>savanna            </td><td style=\"text-align: right;\">       22</td><td>K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.6000000000000000    \n",
    " 0.6000000000000000    \n",
    " 0.4000000000000000                 </td><td>0.7000000000000000   \n",
    " 0.7916666666666667   \n",
    " 0.7916666666666667   \n",
    " 0.6477272727272727   \n",
    " 0.6477272727272727   \n",
    " 0.38888888888888884                  </td><td>0.6785714285714286    \n",
    " 0.68750000000000000    \n",
    " 0.68750000000000000    \n",
    " 0.6160714285714286    \n",
    " 0.6160714285714286    \n",
    " 0.39285714285714285               </td><td>0.6606334841628959    \n",
    " 0.6411483253588517    \n",
    " 0.6411483253588517    \n",
    " 0.5833333333333333    \n",
    " 0.5833333333333333    \n",
    " 0.3891402714932126           </td></tr>\n",
    "<tr><td>steppes            </td><td style=\"text-align: right;\">       12</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.9333333333333333    \n",
    " 0.9333333333333333    \n",
    " 0.8666666666666667                 </td><td>1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 0.875000000000000000   \n",
    " 0.875000000000000000   \n",
    " 0.8000000000000000                  </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.9583333333333333    \n",
    " 0.9583333333333333    \n",
    " 0.9166666666666667               </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 0.9068322981366459    \n",
    " 0.9068322981366459    \n",
    " 0.8295454545454545           </td></tr>\n",
    "<tr><td>drylands           </td><td style=\"text-align: right;\">       16</td><td>AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor              </td><td>0.8666666666666667    \n",
    " 0.8666666666666667    \n",
    " 0.8666666666666667    \n",
    " 0.8666666666666667    \n",
    " 0.7333333333333333    \n",
    " 0.7333333333333333                 </td><td>0.8500000000000001   \n",
    " 0.9166666666666667   \n",
    " 0.9166666666666667   \n",
    " 0.9166666666666667   \n",
    " 0.7232142857142857   \n",
    " 0.7000000000000000                  </td><td>0.8500000000000001    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.75000000000000000    \n",
    " 0.7000000000000000               </td><td>0.8500000000000001    \n",
    " 0.8295454545454545    \n",
    " 0.8295454545454545    \n",
    " 0.8295454545454545    \n",
    " 0.7222222222222221    \n",
    " 0.7000000000000001           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'desert', 'sub_tropical_hot_and_dry_desert', 'rift_valley',\n",
       "       'semi_arid_cold_winter_desert', 'coast_desert'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Desert.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'desert'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['sub_tropical_hot_and_dry_desert', 'rift_valley',\n",
    "       'semi_arid_cold_winter_desert', 'coast_desert']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                       </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>sub_tropical_hot_and_dry_desert</td><td style=\"text-align: right;\">        3</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.8000000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000                 </td><td>0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000                  </td><td>0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000               </td><td>0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445           </td></tr>\n",
    "<tr><td>rift_valley                    </td><td style=\"text-align: right;\">        0</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0<br>     \n",
    " 1.0<br>    \n",
    " 1.0<br>    \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0      <br>         </td><td>1.0 <br>   \n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0    <br>               </td><td>1.0 <br>    \n",
    " 1.0    <br> \n",
    " 1.0    <br> \n",
    " 1.0    <br> \n",
    " 1.0    <br> \n",
    " 1.0         <br>       </td><td>1.0 <br>    \n",
    " 1.0    <br> \n",
    " 1.0    <br> \n",
    " 1.0    <br> \n",
    " 1.0    <br> \n",
    " 1.0           </td></tr>\n",
    "<tr><td>semi_arid_cold_winter_desert   </td><td style=\"text-align: right;\">        2</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000                 </td><td>1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000  \n",
    " 1.0000000000000000   \n",
    " 1.0000000000000000                  </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000               </td><td>1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000\n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000    \n",
    " 1.0000000000000000           </td></tr>\n",
    "<tr><td>coast_desert                   </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.8000000000000000    \n",
    " 0.800000000000000    \n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000\n",
    " 0.8000000000000000    \n",
    " 0.8000000000000000                 </td><td>0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000   \n",
    " 0.4000000000000000                  </td><td>0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000    \n",
    " 0.5000000000000000               </td><td>0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445    \n",
    " 0.4444444444444445           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'marine', 'seas', 'coasts', 'coral_reefs', 'seagrasses',\n",
       "       'large_marine_ecosystem', 'exclusive_economic_zone',\n",
       "       'areas_beyond_national_jurisdiction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Marine.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'marine'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['seas', 'coasts', 'coral_reefs', 'seagrasses',\n",
    "       'large_marine_ecosystem', 'exclusive_economic_zone',\n",
    "       'areas_beyond_national_jurisdiction']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                          </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>seas                              </td><td style=\"text-align: right;\">       13</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.9230769230769231    \n",
    " 0.8461538461538461    \n",
    " 0.8846153846153846    \n",
    " 0.8846153846153846    \n",
    " 0.8076923076923077    \n",
    " 0.8076923076923077                 </td><td>0.96 <br>  \n",
    " 0.6231884057971014   \n",
    " 0.4423076923076923   \n",
    " 0.4423076923076923   \n",
    " 0.4375   <br>\n",
    " 0.4375   <br>               </td><td>0.6666666666666666    \n",
    " 0.6231884057971014    \n",
    " 0.5  <br>  \n",
    " 0.5   <br> \n",
    " 0.45652173913043476    \n",
    " 0.45652173913043476               </td><td>0.7291666666666667    \n",
    " 0.6231884057971014    \n",
    " 0.4693877551020408    \n",
    " 0.4693877551020408    \n",
    " 0.44680851063829785    \n",
    " 0.44680851063829785           </td></tr>\n",
    "<tr><td>coasts                            </td><td style=\"text-align: right;\">       51</td><td>K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.7307692307692307    \n",
    " 0.7307692307692307    \n",
    " 0.6923076923076923    \n",
    " 0.6923076923076923    \n",
    " 0.5769230769230769    \n",
    " 0.34615384615384615                 </td><td>0.7307692307692308   \n",
    " 0.693939393939394   \n",
    " 0.6726190476190477   \n",
    " 0.5666666666666667   \n",
    " 0.4398496240601504   \n",
    " 0.34615384615384615                  </td><td>0.825    \n",
    " 0.7666666666666666    \n",
    " 0.7416666666666667    \n",
    " 0.5666666666666667    \n",
    " 0.4333333333333333    \n",
    " 0.2833333333333333               </td><td>0.7097288676236044    \n",
    " 0.6941176470588235    \n",
    " 0.6601307189542485    \n",
    " 0.5666666666666668    \n",
    " 0.4358974358974359    \n",
    " 0.2950558213716109           </td></tr>\n",
    "<tr><td>coral_reefs                       </td><td style=\"text-align: right;\">       24</td><td>Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.7307692307692307    \n",
    " 0.6538461538461539    \n",
    " 0.8076923076923077    \n",
    " 0.7692307692307693    \n",
    " 0.5    \n",
    " 0.5769230769230769                 </td><td>0.6353383458646616   \n",
    " 0.6151515151515152   \n",
    " 0.9   <br>\n",
    " 0.38461538461538464   \n",
    " 0.4084967320261438   \n",
    " 0.35714285714285715                  </td><td>0.65    \n",
    " 0.6583333333333333    \n",
    " 0.5833333333333334    \n",
    " 0.5    \n",
    " 0.3833333333333333    \n",
    " 0.375               </td><td>0.641025641025641    \n",
    " 0.6067226890756303    \n",
    " 0.5873015873015873    \n",
    " 0.4347826086956522    \n",
    " 0.39099099099099094    \n",
    " 0.3658536585365853           </td></tr>\n",
    "<tr><td>seagrasses                        </td><td style=\"text-align: right;\">        5</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.9230769230769231    \n",
    " 0.9230769230769231    \n",
    " 0.9230769230769231    \n",
    " 0.9230769230769231    \n",
    " 0.8846153846153846    \n",
    " 0.8846153846153846                 </td><td>0.46153846153846156   \n",
    " 0.46153846153846156   \n",
    " 0.46153846153846156   \n",
    " 0.46153846153846156   \n",
    " 0.46   <br>\n",
    " 0.46    <br>              </td><td>0.5   <br> \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4791666666666667    \n",
    " 0.4791666666666667               </td><td>0.48000000000000004    \n",
    " 0.48000000000000004    \n",
    " 0.48000000000000004    \n",
    " 0.48000000000000004    \n",
    " 0.46938775510204084    \n",
    " 0.46938775510204084           </td></tr>\n",
    "<tr><td>large_marine_ecosystem            </td><td style=\"text-align: right;\">       28</td><td>K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Decsision Tree              </td><td>0.6538461538461539    \n",
    " 0.6923076923076923    \n",
    " 0.6153846153846154    \n",
    " 0.5384615384615384    \n",
    " 0.6538461538461539    \n",
    " 0.4230769230769231                 </td><td>0.6   <br>\n",
    " 0.681159420289855   \n",
    " 0.5333333333333333   \n",
    " 0.4095238095238095   \n",
    " 0.3269230769230769   \n",
    " 0.275                  </td><td>0.5784313725490196    \n",
    " 0.5816993464052287    \n",
    " 0.522875816993464    \n",
    " 0.43790849673202614    \n",
    " 0.5    \n",
    " 0.3235294117647059               </td><td>0.5783783783783784    \n",
    " 0.5666666666666667    \n",
    " 0.5112781954887218    \n",
    " 0.4135338345864662    \n",
    " 0.39534883720930236    \n",
    " 0.2972972972972973           </td></tr>\n",
    "<tr><td>exclusive_economic_zone           </td><td style=\"text-align: right;\">        6</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.8076923076923077    \n",
    " 0.8076923076923077    \n",
    " 0.8076923076923077    \n",
    " 0.8076923076923077    \n",
    " 0.7692307692307693    \n",
    " 0.7692307692307693                 </td><td>0.40384615384615385   \n",
    " 0.40384615384615385   \n",
    " 0.40384615384615385   \n",
    " 0.40384615384615385   \n",
    " 0.4 <br>  \n",
    " 0.4     <br>             </td><td>0.5   <br> \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.47619047619047616    \n",
    " 0.47619047619047616               </td><td>0.44680851063829785    \n",
    " 0.44680851063829785    \n",
    " 0.44680851063829785    \n",
    " 0.44680851063829785    \n",
    " 0.43478260869565216    \n",
    " 0.43478260869565216           </td></tr>\n",
    "<tr><td>areas_beyond_national_jurisdiction</td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616                 </td><td>0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5               </td><td>0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wetlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'wetlands', 'mangroves', 'marshes', 'swamps', 'peatlands'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Wetlands.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'wetlands'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['mangroves', 'marshes', 'swamps', 'peatlands']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category  </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>mangroves </td><td style=\"text-align: right;\">       22</td><td>AdaBoost    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes              </td><td>0.8333333333333334    \n",
    " 0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.5833333333333334    \n",
    " 0.6666666666666666    \n",
    " 0.4166666666666667                 </td><td>0.8571428571428572   \n",
    " 0.6857142857142857   \n",
    " 0.6666666666666666   <br>\n",
    " 0.625 <br>  \n",
    " 0.8181818181818181 <br>  \n",
    " 0.45  <br>                </td><td>0.8571428571428572    \n",
    " 0.6857142857142857    \n",
    " 0.6285714285714286    \n",
    " 0.6142857142857143    <br>\n",
    " 0.6    <br>\n",
    " 0.4714285714285714               </td><td>0.8333333333333333    \n",
    " 0.6666666666666666 <br>   \n",
    " 0.625    <br>\n",
    " 0.5804195804195804    \n",
    " 0.5555555555555556    \n",
    " 0.37777777777777777           </td></tr>\n",
    "<tr><td>marshes   </td><td style=\"text-align: right;\">       12</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334                 </td><td>0.7727272727272727   \n",
    " 0.7727272727272727   \n",
    " 0.7727272727272727   \n",
    " 0.7727272727272727   \n",
    " 0.7727272727272727   \n",
    " 0.7727272727272727                  </td><td>0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334    \n",
    " 0.5833333333333334               </td><td>0.49579831932773105    \n",
    " 0.49579831932773105    \n",
    " 0.49579831932773105    \n",
    " 0.49579831932773105    \n",
    " 0.49579831932773105    \n",
    " 0.49579831932773105           </td></tr>\n",
    "<tr><td>swamps    </td><td style=\"text-align: right;\">       11</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.9166666666666666    \n",
    " 0.8333333333333334    \n",
    " 0.8333333333333334    \n",
    " 0.8333333333333334    \n",
    " 0.8333333333333334    \n",
    " 0.6666666666666666                 </td><td>0.95   <br>\n",
    " 0.9090909090909092   \n",
    " 0.9090909090909092   \n",
    " 0.9090909090909092   \n",
    " 0.9090909090909092   \n",
    " 0.5555555555555556                  </td><td>0.8333333333333333    \n",
    " 0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.6666666666666666    \n",
    " 0.5555555555555556              </td><td>0.8736842105263158   <br> \n",
    " 0.7    <br>\n",
    " 0.7    <br>\n",
    " 0.7    <br>\n",
    " 0.7    <br>\n",
    " 0.5555555555555556 <br>          </td></tr>\n",
    "<tr><td>peatlands </td><td style=\"text-align: right;\">        9</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.8333333333333334                 </td><td>0.9545454545454546   \n",
    " 0.9545454545454546   \n",
    " 0.9545454545454546   \n",
    " 0.9545454545454546   \n",
    " 0.9545454545454546  <br> \n",
    " 0.7     <br>             </td><td>0.75   <br> \n",
    " 0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.7       <br>        </td><td>0.8095238095238095    \n",
    " 0.8095238095238095    \n",
    " 0.8095238095238095    \n",
    " 0.8095238095238095    \n",
    " 0.8095238095238095 <br>   \n",
    " 0.7           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human_altered_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'human_altered_areas', 'urban_area', 'rural_area', 'mining_site',\n",
       "       'industrial_site', 'heritage_site', 'entry_exit_ports',\n",
       "       'contaminated_site'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Human_Altered_Areas.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'human_altered_areas'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['urban_area', 'rural_area', 'mining_site',\n",
    "       'industrial_site', 'heritage_site', 'entry_exit_ports',\n",
    "       'contaminated_site']\n",
    "\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category         </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>urban_area       </td><td style=\"text-align: right;\">       52</td><td>K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Decsision Tree              </td><td>0.8059701492537313    \n",
    " 0.8059701492537313    \n",
    " 0.7313432835820896    \n",
    " 0.7313432835820896    \n",
    " 0.8059701492537313    \n",
    " 0.7014925373134329                 </td><td>0.718939393939394   \n",
    " 0.7277542372881356   \n",
    " 0.6258823529411764   \n",
    " 0.6134615384615385   \n",
    " 0.7797619047619048   \n",
    " 0.5705128205128205                  </td><td>0.6852564102564103    \n",
    " 0.6378205128205128    \n",
    " 0.6371794871794871    \n",
    " 0.6134615384615385    \n",
    " 0.5903846153846154    \n",
    " 0.5705128205128205               </td><td>0.6985115957078574    \n",
    " 0.6588327457892675    \n",
    " 0.6305147058823529    \n",
    " 0.6134615384615385    \n",
    " 0.6013729977116705    \n",
    " 0.5705128205128205           </td></tr>\n",
    "<tr><td>rural_area       </td><td style=\"text-align: right;\">       97</td><td>Stochastic Gradient Descent    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes              </td><td>0.8208955223880597    \n",
    " 0.8208955223880597    \n",
    " 0.746268656716418    \n",
    " 0.746268656716418    \n",
    " 0.7164179104477612    \n",
    " 0.6567164179104478                 </td><td>0.8209706959706959   \n",
    " 0.8255159474671669   \n",
    " 0.7437275985663083   \n",
    " 0.7453703703703703   \n",
    " 0.7137096774193548   \n",
    " 0.659375 <br>                  </td><td>0.8157657657657658    \n",
    " 0.8126126126126125    \n",
    " 0.745045045045045    \n",
    " 0.7387387387387387    \n",
    " 0.7148648648648648    \n",
    " 0.6608108108108108               </td><td>0.8176043557168784    \n",
    " 0.8159340659340659    \n",
    " 0.7442173815405344    \n",
    " 0.7404875825928456    \n",
    " 0.7141253087805972    \n",
    " 0.6564102564102565           </td></tr>\n",
    "<tr><td>mining_site      </td><td style=\"text-align: right;\">       16</td><td>K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.9552238805970149    \n",
    " 0.9104477611940298    \n",
    " 0.9402985074626866    \n",
    " 0.9402985074626866    \n",
    " 0.9104477611940298    \n",
    " 0.8805970149253731                 </td><td>0.976923076923077   \n",
    " 0.6758064516129032   \n",
    " 0.9696969696969697   \n",
    " 0.9696969696969697   \n",
    " 0.6354166666666666   \n",
    " 0.567741935483871                  </td><td>0.7   <br> \n",
    " 0.6758064516129032 <br>   \n",
    " 0.6<br>    \n",
    " 0.6  <br>  \n",
    " 0.5838709677419355    \n",
    " 0.567741935483871               </td><td>0.7739032620922385    \n",
    " 0.6758064516129033    \n",
    " 0.6510416666666667    \n",
    " 0.6510416666666667    \n",
    " 0.6011904761904762    \n",
    " 0.567741935483871           </td></tr>\n",
    "<tr><td>industrial_site  </td><td style=\"text-align: right;\">       79</td><td>K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes              </td><td>0.8656716417910447    \n",
    " 0.8507462686567164    \n",
    " 0.835820895522388    \n",
    " 0.8208955223880597    \n",
    " 0.7910447761194029    \n",
    " 0.7313432835820896                 </td><td>0.8543956043956045   \n",
    " 0.8404761904761905   \n",
    " 0.8398936170212765   \n",
    " 0.8085714285714285<br>   \n",
    " 0.875   <br>\n",
    " 0.7171052631578947                  </td><td>0.8685714285714285    \n",
    " 0.8404761904761905    \n",
    " 0.8042857142857143    \n",
    " 0.8085714285714285    <br>\n",
    " 0.72    <br>\n",
    " 0.6885714285714286               </td><td>0.859538784067086    \n",
    " 0.8404761904761906    \n",
    " 0.8159800249687891    \n",
    " 0.8085714285714285    \n",
    " 0.7341269841269842    \n",
    " 0.6954545454545454           </td></tr>\n",
    "<tr><td>heritage_site    </td><td style=\"text-align: right;\">        2</td><td>Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9850746268656716    \n",
    " 0.9104477611940298    \n",
    " 0.8955223880597015                 </td><td>1.0  <br> \n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5   <br>\n",
    " 0.5   <br>\n",
    " 0.5       <br>           </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4925373134328358    \n",
    " 0.4552238805970149    \n",
    " 0.44776119402985076               </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.49624060150375937<br>    \n",
    " 0.4765625    <br>\n",
    " 0.4724409448818898           </td></tr>\n",
    "<tr><td>entry_exit_ports </td><td style=\"text-align: right;\">        2</td><td>Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.9850746268656716    \n",
    " 0.9850746268656716    \n",
    " 0.9850746268656716    \n",
    " 0.9701492537313433    \n",
    " 0.9701492537313433    \n",
    " 0.9552238805970149                 </td><td>0.4925373134328358   \n",
    " 0.4925373134328358   \n",
    " 0.4925373134328358   \n",
    " 0.49242424242424243   \n",
    " 0.49242424242424243   \n",
    " 0.49230769230769234                  </td><td>0.5 <br>   \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.49242424242424243    \n",
    " 0.49242424242424243    \n",
    " 0.48484848484848486               </td><td>0.49624060150375937    \n",
    " 0.49624060150375937    \n",
    " 0.49624060150375937    \n",
    " 0.49242424242424243    \n",
    " 0.49242424242424243    \n",
    " 0.4885496183206107           </td></tr>\n",
    "<tr><td>contaminated_site</td><td style=\"text-align: right;\">       11</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor              </td><td>0.9850746268656716    \n",
    " 0.9850746268656716    \n",
    " 0.9552238805970149    \n",
    " 0.9701492537313433    \n",
    " 0.9402985074626866    \n",
    " 0.9701492537313433                 </td><td>0.9924242424242424   \n",
    " 0.9924242424242424 <br>  \n",
    " 0.7   <br>\n",
    " 0.7423076923076923   \n",
    " 0.6170634920634921   \n",
    " 0.48507462686567165                  </td><td>0.75  <br>  \n",
    " 0.75    <br>\n",
    " 0.976923076923077    \n",
    " 0.7423076923076923    \n",
    " 0.726923076923077 <br>   \n",
    " 0.5         <br>      </td><td>0.8295165394402035    \n",
    " 0.8295165394402035    \n",
    " 0.7739032620922385    \n",
    " 0.7423076923076923    \n",
    " 0.6510416666666666    \n",
    " 0.49242424242424243           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
