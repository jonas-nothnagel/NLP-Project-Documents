{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''basics'''\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath(os.path.join('..', 'src')))\n",
    "sys.setrecursionlimit(20500)\n",
    "import pandas as pd\n",
    "import pickle5 as pickle\n",
    "import numpy as np\n",
    "\n",
    "'''Plotting'''\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "'''features'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "'''Classifiers'''\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "'''Metrics/Evaluation'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn_hierarchical_classification.classifier import HierarchicalClassifier\n",
    "from sklearn_hierarchical_classification.constants import ROOT\n",
    "from sklearn_hierarchical_classification.metrics import h_fbeta_score, multi_labeled\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enabling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and holdout data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'enabling', 'mainstream', 'alignment', 'advocacy_towards_policy_makers',\n",
       "       'public_campaign', 'community_engagement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/enabling.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mainstream</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alignment</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>advocacy_towards_policy_makers</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>public_campaign</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>community_engagement</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         category  number_of_inputs\n",
       "0                      mainstream                69\n",
       "1                       alignment                13\n",
       "2  advocacy_towards_policy_makers                14\n",
       "3                 public_campaign                 7\n",
       "4            community_engagement                32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'enabling'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats.plot(x='category', y='number_of_inputs', kind='bar', legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of comments per category\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('category', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many comments have multi labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of categories')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rowsums = df.iloc[:,4:].sum(axis=1)\n",
    "x=rowsums.value_counts()\n",
    "#plot\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of categories', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The distribution of the number of words in input texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3aa56adb70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lens = df.all_text_clean.str.len()\n",
    "lens.hist(bins = np.arange(0,5000,50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holding out 5 rows from the original dataframe for prediction at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_holdout = df.iloc[:5]\n",
    "\n",
    "df = df.iloc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'enabling', 'mainstream', 'alignment', 'advocacy_towards_policy_makers',\n",
       "       'public_campaign', 'community_engagement'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['mainstream', 'alignment', 'advocacy_towards_policy_makers',\n",
    "       'public_campaign', 'community_engagement']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train multiple ML models / OneVsRest multi-label strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "#print (tabulate(rows, header, tablefmt='html'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                      </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>mainstream                    </td><td style=\"text-align: right;\">       69</td><td>Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost              </td><td>0.8333333333333334    \n",
    " 0.9166666666666666    \n",
    " 0.8333333333333334 <br>   \n",
    " 0.875    <br>\n",
    " 0.875    <br>\n",
    " 0.875        <br>         </td><td>0.7142857142857143   \n",
    " 0.9565217391304348   \n",
    " 0.6736842105263158 <br>   \n",
    " 0.4375   <br>\n",
    " 0.4375   <br>\n",
    " 0.4375       <br>           </td><td>0.9047619047619048    \n",
    " 0.6666666666666666    \n",
    " 0.7619047619047619    \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.7473684210526316    \n",
    " 0.7272727272727273 <br>   \n",
    " 0.7    <br>\n",
    " 0.4666666666666667    \n",
    " 0.4666666666666667    \n",
    " 0.4666666666666667           </td></tr>\n",
    "<tr><td>alignment                     </td><td style=\"text-align: right;\">       13</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.8333333333333334    \n",
    " 0.875    <br>\n",
    " 0.875    <br>\n",
    " 0.875    <br>\n",
    " 0.875    <br>\n",
    " 0.875        <br>         </td><td>0.7   <br>\n",
    " 0.9347826086956521   \n",
    " 0.9347826086956521   \n",
    " 0.9347826086956521   \n",
    " 0.9347826086956521   \n",
    " 0.9347826086956521                  </td><td>0.7    <br>\n",
    " 0.625    <br>\n",
    " 0.625    <br>\n",
    " 0.625    <br>\n",
    " 0.625    <br>\n",
    " 0.625        <br>       </td><td>0.7    <br>\n",
    " 0.6651162790697674    \n",
    " 0.6651162790697674    \n",
    " 0.6651162790697674    \n",
    " 0.6651162790697674    \n",
    " 0.6651162790697674           </td></tr>\n",
    "<tr><td>advocacy_towards_policy_makers</td><td style=\"text-align: right;\">       14</td><td>Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.7083333333333334    \n",
    " 0.7083333333333334    \n",
    " 0.8333333333333334    \n",
    " 0.8333333333333334    \n",
    " 0.7916666666666666    \n",
    " 0.7083333333333334                 </td><td>0.5840336134453781   \n",
    " 0.5210526315789473   \n",
    " 0.4166666666666667   \n",
    " 0.4166666666666667   \n",
    " 0.41304347826086957   \n",
    " 0.40476190476190477                  </td><td>0.625  <br>  \n",
    " 0.525    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.475    <br>\n",
    " 0.425        <br>       </td><td>0.5872235872235871    \n",
    " 0.5213675213675214    \n",
    " 0.45454545454545453    \n",
    " 0.45454545454545453    \n",
    " 0.44186046511627913    \n",
    " 0.41463414634146345           </td></tr>\n",
    "<tr><td>public_campaign               </td><td style=\"text-align: right;\">        7</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes              </td><td>0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.9166666666666666    \n",
    " 0.9166666666666666 <br>    \n",
    " 0.875        <br>         </td><td>0.4583333333333333   \n",
    " 0.4583333333333333   \n",
    " 0.4583333333333333   \n",
    " 0.4583333333333333   \n",
    " 0.4583333333333333   \n",
    " 0.45652173913043476                  </td><td>0.5 <br>   \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4772727272727273               </td><td>0.4782608695652174    \n",
    " 0.4782608695652174    \n",
    " 0.4782608695652174    \n",
    " 0.4782608695652174    \n",
    " 0.4782608695652174    \n",
    " 0.4666666666666666           </td></tr>\n",
    "<tr><td>community_engagement          </td><td style=\"text-align: right;\">       32</td><td>AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest    \n",
    " Decsision Tree              </td><td>0.8333333333333334    \n",
    " 0.7916666666666666 <br>   \n",
    " 0.75    <br>\n",
    " 0.6666666666666666    \n",
    " 0.7083333333333334  <br>  \n",
    " 0.625                 </td><td>0.8888888888888888   \n",
    " 0.8109243697478992   \n",
    " 0.75   \n",
    " 0.71875   \n",
    " 0.8333333333333333   \n",
    " 0.6428571428571428                  </td><td>0.8    \n",
    " 0.7642857142857142    \n",
    " 0.7285714285714285    \n",
    " 0.7    \n",
    " 0.65    \n",
    " 0.5642857142857143               </td><td>0.8125    \n",
    " 0.7722960151802656    \n",
    " 0.7333333333333332    \n",
    " 0.6643356643356644    \n",
    " 0.6307692307692307    \n",
    " 0.5252747252747253           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tundra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'tundra', 'alpine_tundra'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Tundra.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alpine_tundra</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category  number_of_inputs\n",
       "0  alpine_tundra                 1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'tundra'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conserved_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'conserved_areas', '_indigenous_protected_and_conserved_areas_ipcas_x',\n",
       "       '_indigenous_protected_and_conserved_areas_ipcas_y',\n",
       "       'marine_and_coastal_protected_areas', 'terrestrial_protected_areas',\n",
       "       'indigenous_and_communities_conserved_areas_icca',\n",
       "       'transboundary_conservation_areas', 'productive_landscapes_seascapes',\n",
       "       'key_biodiversity_areas_kba',\n",
       "       '_important_bird_and_biodiversity_areas_ibas',\n",
       "       'specially_protected_areas_spas',\n",
       "       '_indigenous_protected_and_conserved_areas_ipcas',\n",
       "       'protected_areas_network',\n",
       "       'oecm_other_effective_area_based_conservation_measures',\n",
       "       'locally_managed_marine_areas'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Conserved_Areas.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_indigenous_protected_and_conserved_areas_ipcas_x</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_indigenous_protected_and_conserved_areas_ipcas_y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>marine_and_coastal_protected_areas</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>terrestrial_protected_areas</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indigenous_and_communities_conserved_areas_icca</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transboundary_conservation_areas</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>productive_landscapes_seascapes</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>key_biodiversity_areas_kba</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>_important_bird_and_biodiversity_areas_ibas</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>specially_protected_areas_spas</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>_indigenous_protected_and_conserved_areas_ipcas</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>protected_areas_network</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>oecm_other_effective_area_based_conservation_m...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>locally_managed_marine_areas</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             category  number_of_inputs\n",
       "0   _indigenous_protected_and_conserved_areas_ipcas_x                 2\n",
       "1   _indigenous_protected_and_conserved_areas_ipcas_y                 1\n",
       "2                  marine_and_coastal_protected_areas                48\n",
       "3                         terrestrial_protected_areas                76\n",
       "4     indigenous_and_communities_conserved_areas_icca                23\n",
       "5                    transboundary_conservation_areas                12\n",
       "6                     productive_landscapes_seascapes                56\n",
       "7                          key_biodiversity_areas_kba                51\n",
       "8         _important_bird_and_biodiversity_areas_ibas                12\n",
       "9                      specially_protected_areas_spas                14\n",
       "10    _indigenous_protected_and_conserved_areas_ipcas                 0\n",
       "11                            protected_areas_network                 7\n",
       "12  oecm_other_effective_area_based_conservation_m...                18\n",
       "13                       locally_managed_marine_areas                15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'conserved_areas'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['_indigenous_protected_and_conserved_areas_ipcas_x',\n",
    "       '_indigenous_protected_and_conserved_areas_ipcas_y',\n",
    "       'marine_and_coastal_protected_areas', 'terrestrial_protected_areas',\n",
    "       'indigenous_and_communities_conserved_areas_icca',\n",
    "       'transboundary_conservation_areas', 'productive_landscapes_seascapes',\n",
    "       'key_biodiversity_areas_kba',\n",
    "       '_important_bird_and_biodiversity_areas_ibas',\n",
    "       'specially_protected_areas_spas',\n",
    "       '_indigenous_protected_and_conserved_areas_ipcas',\n",
    "       'protected_areas_network',\n",
    "       'oecm_other_effective_area_based_conservation_measures',\n",
    "       'locally_managed_marine_areas']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                                             </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>_indigenous_protected_and_conserved_areas_ipcas_x    </td><td style=\"text-align: right;\">        2</td><td>Random Forest    <br>\n",
    " Decsision Tree   <br> \n",
    " Gaussian Naive Bayes <br>   \n",
    " K Nearest Neighbor <br>   \n",
    " Stochastic Gradient Descent  <br>  \n",
    " AdaBoost              </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174                 </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5   <br>\n",
    " 0.5       <br>           </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4891304347826087    \n",
    " 0.4891304347826087               </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945           </td></tr>\n",
    "<tr><td>_indigenous_protected_and_conserved_areas_ipcas_y    </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0                  </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0           </td></tr>\n",
    "<tr><td>marine_and_coastal_protected_areas                   </td><td style=\"text-align: right;\">       48</td><td>Random Forest    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.8913043478260869    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8478260869565217    \n",
    " 0.8043478260869565    \n",
    " 0.782608695652174                 </td><td>0.9418604651162791   \n",
    " 0.7083333333333333   \n",
    " 0.7083333333333333   \n",
    " 0.7390243902439024   \n",
    " 0.6681681681681682   \n",
    " 0.5916666666666667                  </td><td>0.6875    \n",
    " 0.7467105263157895    \n",
    " 0.7467105263157895    \n",
    " 0.6611842105263157    \n",
    " 0.6842105263157895    \n",
    " 0.5723684210526316               </td><td>0.7418630751964086    \n",
    " 0.7237237237237237    \n",
    " 0.7237237237237237    \n",
    " 0.6864654333008764    \n",
    " 0.6752941176470588    \n",
    " 0.5787545787545788           </td></tr>\n",
    "<tr><td>terrestrial_protected_areas                          </td><td style=\"text-align: right;\">       76</td><td>K Nearest Neighbor    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent              </td><td>0.6521739130434783    \n",
    " 0.6521739130434783    \n",
    " 0.6304347826086957    \n",
    " 0.6086956521739131    \n",
    " 0.5652173913043478    \n",
    " 0.5217391304347826                 </td><td>0.6519230769230769   \n",
    " 0.6646825396825397   \n",
    " 0.6304347826086957   \n",
    " 0.6383928571428572   \n",
    " 0.5791666666666666   \n",
    " 0.5625                  </td><td>0.6496212121212122    \n",
    " 0.6571969696969697    \n",
    " 0.6306818181818181    \n",
    " 0.6174242424242424    \n",
    " 0.571969696969697    \n",
    " 0.5359848484848485               </td><td>0.6495238095238096    \n",
    " 0.6495238095238095    \n",
    " 0.630260047281324    \n",
    " 0.5964912280701754    \n",
    " 0.5576923076923077    \n",
    " 0.47291666666666665           </td></tr>\n",
    "<tr><td>indigenous_and_communities_conserved_areas_icca      </td><td style=\"text-align: right;\">       23</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.782608695652174    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8043478260869565    \n",
    " 0.8043478260869565    \n",
    " 0.782608695652174                 </td><td>0.5916666666666667   \n",
    " 0.6704545454545454   \n",
    " 0.41304347826086957   \n",
    " 0.4111111111111111   \n",
    " 0.4111111111111111   \n",
    " 0.4090909090909091                  </td><td>0.5723684210526316    \n",
    " 0.549342105263158    \n",
    " 0.5    \n",
    " 0.4868421052631579    \n",
    " 0.4868421052631579    \n",
    " 0.47368421052631576               </td><td>0.5787545787545788    \n",
    " 0.551219512195122    \n",
    " 0.45238095238095233    \n",
    " 0.4457831325301205    \n",
    " 0.4457831325301205    \n",
    " 0.43902439024390244           </td></tr>\n",
    "<tr><td>transboundary_conservation_areas                     </td><td style=\"text-align: right;\">       12</td><td>Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost              </td><td>0.9782608695652174    \n",
    " 0.8913043478260869    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348                 </td><td>0.75   <br>\n",
    " 0.5833333333333334   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4888888888888889   \n",
    " 0.4888888888888889                  </td><td>0.9888888888888889    \n",
    " 0.9444444444444444<br>    \n",
    " 0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889               </td><td>0.8277153558052435    \n",
    " 0.6134453781512605    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889           </td></tr>\n",
    "<tr><td>productive_landscapes_seascapes                      </td><td style=\"text-align: right;\">       56</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Random Forest              </td><td>0.717391304347826    \n",
    " 0.6956521739130435    \n",
    " 0.6521739130434783    \n",
    " 0.717391304347826    \n",
    " 0.5869565217391305    \n",
    " 0.6956521739130435                 </td><td>0.6470588235294117   \n",
    " 0.6247086247086246   \n",
    " 0.6024340770791075   \n",
    " 0.631578947368421   \n",
    " 0.5229166666666667   \n",
    " 0.35555555555555557                  </td><td>0.6398601398601399    \n",
    " 0.6247086247086246    \n",
    " 0.6177156177156178    \n",
    " 0.5932400932400932    \n",
    " 0.5256410256410257    \n",
    " 0.48484848484848486               </td><td>0.6429850746268657    \n",
    " 0.6247086247086246    \n",
    " 0.6043010752688172    \n",
    " 0.5989268947015426    \n",
    " 0.5216201423097975    \n",
    " 0.41025641025641024           </td></tr>\n",
    "<tr><td>key_biodiversity_areas_kba                           </td><td style=\"text-align: right;\">       51</td><td>AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor              </td><td>0.6956521739130435    \n",
    " 0.7391304347826086    \n",
    " 0.6304347826086957    \n",
    " 0.6739130434782609    \n",
    " 0.7391304347826086    \n",
    " 0.6086956521739131                 </td><td>0.6490872210953347   \n",
    " 0.6696696696696697   \n",
    " 0.6038461538461539   \n",
    " 0.5906862745098039   \n",
    " 0.8666666666666667   \n",
    " 0.4935064935064935                  </td><td>0.6713286713286714    \n",
    " 0.6317016317016317    \n",
    " 0.6258741258741258    \n",
    " 0.5862470862470862    \n",
    " 0.5384615384615384    \n",
    " 0.4941724941724942               </td><td>0.6537634408602151    \n",
    " 0.6415584415584416    \n",
    " 0.5983564458140729    \n",
    " 0.5880597014925373    \n",
    " 0.49450549450549447    \n",
    " 0.49264705882352944           </td></tr>\n",
    "<tr><td>_important_bird_and_biodiversity_areas_ibas          </td><td style=\"text-align: right;\">       12</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9565217391304348                 </td><td>0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4888888888888889                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4888888888888889               </td><td>0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4888888888888889           </td></tr>\n",
    "<tr><td>specially_protected_areas_spas                       </td><td style=\"text-align: right;\">       14</td><td>Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree              </td><td>0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9347826086956522    \n",
    " 0.8695652173913043                 </td><td>0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4777777777777778   \n",
    " 0.47619047619047616                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.48863636363636365    \n",
    " 0.45454545454545453               </td><td>0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4831460674157304    \n",
    " 0.46511627906976744           </td></tr>\n",
    "<tr><td>_indigenous_protected_and_conserved_areas_ipcas      </td><td style=\"text-align: right;\">        0</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0 <br>   \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>   </td></tr>\n",
    "<tr><td>protected_areas_network                              </td><td style=\"text-align: right;\">        7</td><td>Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree              </td><td>0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9565217391304348    \n",
    " 0.9347826086956522                 </td><td>0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4888888888888889   \n",
    " 0.48863636363636365                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4888888888888889    \n",
    " 0.4777777777777778               </td><td>0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4888888888888889    \n",
    " 0.4831460674157304           </td></tr>\n",
    "<tr><td>oecm_other_effective_area_based_conservation_measures</td><td style=\"text-align: right;\">       18</td><td>Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree              </td><td>0.9130434782608695    \n",
    " 0.9130434782608695    \n",
    " 0.8913043478260869    \n",
    " 0.8913043478260869    \n",
    " 0.8260869565217391    \n",
    " 0.8043478260869565                 </td><td>0.45652173913043476   \n",
    " 0.45652173913043476   \n",
    " 0.45555555555555555   \n",
    " 0.45555555555555555   \n",
    " 0.4523809523809524   \n",
    " 0.45121951219512196                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.4880952380952381    \n",
    " 0.4880952380952381    \n",
    " 0.4523809523809524    \n",
    " 0.44047619047619047               </td><td>0.47727272727272724    \n",
    " 0.47727272727272724    \n",
    " 0.47126436781609193    \n",
    " 0.47126436781609193    \n",
    " 0.4523809523809524    \n",
    " 0.44578313253012053           </td></tr>\n",
    "<tr><td>locally_managed_marine_areas                         </td><td style=\"text-align: right;\">       15</td><td>AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.9782608695652174    \n",
    " 0.8695652173913043                 </td><td>0.75   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4891304347826087   \n",
    " 0.4878048780487805                  </td><td>0.9888888888888889    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4444444444444444               </td><td>0.8277153558052435    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.4945054945054945    \n",
    " 0.46511627906976744           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finance Economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'finance_economy', 'nature_finance', 'energy_finance',\n",
       "       'circular_economy', 'blue_economy', 'green_economy', 'fiscal_planning',\n",
       "       'new_other_financial_schemes_mechanism'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Finance_Economy.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>number_of_inputs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nature_finance</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>energy_finance</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>circular_economy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue_economy</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>green_economy</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fiscal_planning</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new_other_financial_schemes_mechanism</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                category  number_of_inputs\n",
       "0                         nature_finance                42\n",
       "1                         energy_finance                62\n",
       "2                       circular_economy                 1\n",
       "3                           blue_economy                 8\n",
       "4                          green_economy                14\n",
       "5                        fiscal_planning                28\n",
       "6  new_other_financial_schemes_mechanism                49"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'finance_economy'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['nature_finance', 'energy_finance',\n",
    "       'circular_economy', 'blue_economy', 'green_economy', 'fiscal_planning',\n",
    "       'new_other_financial_schemes_mechanism']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                             </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>nature_finance                       </td><td style=\"text-align: right;\">       42</td><td>Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Random Forest    \n",
    " Stochastic Gradient Descent              </td><td>0.8367346938775511    \n",
    " 0.7755102040816326    \n",
    " 0.7346938775510204    \n",
    " 0.8163265306122449    \n",
    " 0.8163265306122449    \n",
    " 0.7346938775510204                 </td><td>0.7792792792792793   \n",
    " 0.6997863247863247   \n",
    " 0.6868421052631579   \n",
    " 0.8090909090909091   \n",
    " 0.9021739130434783   \n",
    " 0.5471014492753623                  </td><td>0.7792792792792793    \n",
    " 0.7105855855855856    \n",
    " 0.7398648648648649    \n",
    " 0.6531531531531531    \n",
    " 0.625    \n",
    " 0.5146396396396397               </td><td>0.7792792792792793    \n",
    " 0.7046575342465753    \n",
    " 0.693307655272027    \n",
    " 0.6797385620915033    \n",
    " 0.6457831325301204    \n",
    " 0.48835341365461854           </td></tr>\n",
    "<tr><td>energy_finance                       </td><td style=\"text-align: right;\">       62</td><td>Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor              </td><td>0.9591836734693877    \n",
    " 0.9591836734693877    \n",
    " 0.9591836734693877    \n",
    " 0.9387755102040817    \n",
    " 0.9387755102040817    \n",
    " 0.8775510204081632                 </td><td>0.9696969696969697   \n",
    " 0.9696969696969697   \n",
    " 0.9696969696969697   \n",
    " 0.9558823529411764   \n",
    " 0.9558823529411764   \n",
    " 0.9189189189189189                  </td><td>0.9444444444444444    \n",
    " 0.9444444444444444    \n",
    " 0.9444444444444444    \n",
    " 0.9166666666666667    \n",
    " 0.9166666666666667    \n",
    " 0.8333333333333333               </td><td>0.9549632352941176    \n",
    " 0.9549632352941176    \n",
    " 0.9549632352941176    \n",
    " 0.9314685314685315    \n",
    " 0.9314685314685315    \n",
    " 0.8558823529411765           </td></tr>\n",
    "<tr><td>circular_economy                     </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0                 </td><td>1.0   \n",
    " 1.0   \n",
    " 1.0   \n",
    " 1.0   \n",
    " 1.0   \n",
    " 1.0                  </td><td>1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0               </td><td>1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0    \n",
    " 1.0           </td></tr>\n",
    "<tr><td>blue_economy                         </td><td style=\"text-align: right;\">        8</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9387755102040817    \n",
    " 0.9387755102040817    \n",
    " 0.9387755102040817    \n",
    " 0.9387755102040817    \n",
    " 0.9387755102040817    \n",
    " 0.9183673469387755                 </td><td>0.46938775510204084   \n",
    " 0.46938775510204084   \n",
    " 0.46938775510204084   \n",
    " 0.46938775510204084   \n",
    " 0.46938775510204084   \n",
    " 0.46875                  </td><td>0.5    \n",
    " 0.5    \n",
    " 0.5    \n",
    " 0.5    \n",
    " 0.5    \n",
    " 0.4891304347826087               </td><td>0.4842105263157895    \n",
    " 0.4842105263157895    \n",
    " 0.4842105263157895    \n",
    " 0.4842105263157895    \n",
    " 0.4842105263157895    \n",
    " 0.4787234042553192           </td></tr>\n",
    "<tr><td>green_economy                        </td><td style=\"text-align: right;\">       14</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost              </td><td>0.9387755102040817    \n",
    " 0.8979591836734694    \n",
    " 0.8367346938775511    \n",
    " 0.9591836734693877    \n",
    " 0.9591836734693877    \n",
    " 0.9591836734693877                 </td><td>0.6557971014492754   \n",
    " 0.5886363636363636   \n",
    " 0.5503048780487805   \n",
    " 0.47959183673469385   \n",
    " 0.47959183673469385   \n",
    " 0.47959183673469385                  </td><td>0.7287234042553192    \n",
    " 0.7074468085106382    \n",
    " 0.675531914893617    \n",
    " 0.5    \n",
    " 0.5    \n",
    " 0.5               </td><td>0.6838709677419355    \n",
    " 0.6153846153846154    \n",
    " 0.5545454545454546    \n",
    " 0.4895833333333333    \n",
    " 0.4895833333333333    \n",
    " 0.4895833333333333           </td></tr>\n",
    "<tr><td>fiscal_planning                      </td><td style=\"text-align: right;\">       28</td><td>K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " Random Forest              </td><td>0.8571428571428571    \n",
    " 0.8775510204081632    \n",
    " 0.8367346938775511    \n",
    " 0.7959183673469388    \n",
    " 0.7755102040816326    \n",
    " 0.8775510204081632                 </td><td>0.7243589743589743   \n",
    " 0.75   \n",
    " 0.6847222222222222   \n",
    " 0.6166666666666667   \n",
    " 0.5987179487179487   \n",
    " 0.9375                  </td><td>0.7976190476190477    \n",
    " 0.75    \n",
    " 0.7261904761904762    \n",
    " 0.6428571428571428    \n",
    " 0.6309523809523809    \n",
    " 0.5714285714285714               </td><td>0.7509077705156135    \n",
    " 0.75    \n",
    " 0.7012195121951219    \n",
    " 0.6265243902439024    \n",
    " 0.6085693536673928    \n",
    " 0.5916666666666667           </td></tr>\n",
    "<tr><td>new_other_financial_schemes_mechanism</td><td style=\"text-align: right;\">       49</td><td>Random Forest    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.8775510204081632    \n",
    " 0.7959183673469388    \n",
    " 0.7551020408163265    \n",
    " 0.7755102040816326    \n",
    " 0.7551020408163265    \n",
    " 0.6326530612244898                 </td><td>0.8690476190476191   \n",
    " 0.7334558823529411   \n",
    " 0.7035087719298245   \n",
    " 0.6928571428571428   \n",
    " 0.6884191176470589   \n",
    " 0.5745614035087719                  </td><td>0.7595693779904307    \n",
    " 0.8038277511961722    \n",
    " 0.777511961722488    \n",
    " 0.7260765550239234    \n",
    " 0.7452153110047848    \n",
    " 0.6016746411483254               </td><td>0.7958333333333333    \n",
    " 0.75    \n",
    " 0.7117647058823529    \n",
    " 0.7046575342465753    \n",
    " 0.7    \n",
    " 0.5676470588235294           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Governance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'governance', 'institutional_framework', 'partnerships',\n",
       "       'transboundary_governance', 'inter_sectoral_coordination',\n",
       "       'adaptive_governance', '_community_governance', '_cooperative',\n",
       "       '_co_management'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/governance.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'governance'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['institutional_framework', 'partnerships',\n",
    "       'transboundary_governance', 'inter_sectoral_coordination',\n",
    "       'adaptive_governance', '_community_governance', '_cooperative',\n",
    "       '_co_management']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                   </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>institutional_framework    </td><td style=\"text-align: right;\">      162</td><td>Random Forest    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.8591549295774648    \n",
    " 0.7605633802816901    \n",
    " 0.7746478873239436    \n",
    " 0.7183098591549296    \n",
    " 0.7605633802816901    \n",
    " 0.704225352112676                 </td><td>0.9253731343283582   \n",
    " 0.6410675381263616   \n",
    " 0.6441102756892231   \n",
    " 0.6343085106382979   \n",
    " 0.6285714285714286   \n",
    " 0.5966666666666667                  </td><td>0.6428571428571428    \n",
    " 0.6622807017543859    \n",
    " 0.6441102756892231    \n",
    " 0.6898496240601504    \n",
    " 0.6353383458646616    \n",
    " 0.6271929824561404               </td><td>0.681899641577061    \n",
    " 0.6492298750363267    \n",
    " 0.6441102756892231    \n",
    " 0.6406882591093118    \n",
    " 0.6316753127860848    \n",
    " 0.6018691588785048           </td></tr>\n",
    "<tr><td>partnerships               </td><td style=\"text-align: right;\">       79</td><td>K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes              </td><td>0.6619718309859155    \n",
    " 0.6338028169014085    \n",
    " 0.6056338028169014    \n",
    " 0.5492957746478874    \n",
    " 0.6056338028169014    \n",
    " 0.5633802816901409                 </td><td>0.6547619047619048   \n",
    " 0.6083333333333334   \n",
    " 0.5797872340425532   \n",
    " 0.503921568627451   \n",
    " 0.5559701492537313   \n",
    " 0.46505376344086025                  </td><td>0.6025747508305648    \n",
    " 0.5917774086378738    \n",
    " 0.574750830564784    \n",
    " 0.5033222591362125    \n",
    " 0.5124584717607974    \n",
    " 0.4838039867109634               </td><td>0.5942857142857143    \n",
    " 0.5908687943262412    \n",
    " 0.5752136752136752    \n",
    " 0.4964539007092198    \n",
    " 0.4352272727272727    \n",
    " 0.43346203346203344           </td></tr>\n",
    "<tr><td>transboundary_governance   </td><td style=\"text-align: right;\">       24</td><td>Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9577464788732394    \n",
    " 0.9154929577464789    \n",
    " 0.9154929577464789    \n",
    " 0.9154929577464789    \n",
    " 0.9014084507042254    \n",
    " 0.7183098591549296                 </td><td>0.9129464285714286   \n",
    " 0.8025641025641026   \n",
    " 0.8025641025641026   \n",
    " 0.9565217391304348   \n",
    " 0.95   \n",
    " 0.47431077694235585                  </td><td>0.8670634920634921    \n",
    " 0.7341269841269842    \n",
    " 0.7341269841269842    \n",
    " 0.625    \n",
    " 0.5625    \n",
    " 0.4593253968253968               </td><td>0.8881889763779527    \n",
    " 0.7622767857142858    \n",
    " 0.7622767857142858    \n",
    " 0.6772727272727272    \n",
    " 0.5847953216374269    \n",
    " 0.46212121212121215           </td></tr>\n",
    "<tr><td>inter_sectoral_coordination</td><td style=\"text-align: right;\">       51</td><td>K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest              </td><td>0.7746478873239436    \n",
    " 0.8028169014084507    \n",
    " 0.7746478873239436    \n",
    " 0.7464788732394366    \n",
    " 0.7464788732394366    \n",
    " 0.8450704225352113                 </td><td>0.5935013262599469   \n",
    " 0.6021505376344086   \n",
    " 0.5696969696969697   \n",
    " 0.5464190981432361   \n",
    " 0.5159090909090909   \n",
    " 0.4225352112676056                  </td><td>0.6068181818181818    \n",
    " 0.5863636363636364    \n",
    " 0.5696969696969697    \n",
    " 0.553030303030303   <br> \n",
    " 0.5159090909090909    <br>\n",
    " 0.5               </td><td>0.5988700564971752    \n",
    " 0.5926229508196722    \n",
    " 0.5696969696969697    \n",
    " 0.548728813559322    \n",
    " 0.5159090909090909    \n",
    " 0.4580152671755725           </td></tr>\n",
    "<tr><td>adaptive_governance        </td><td style=\"text-align: right;\">       25</td><td>Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.8873239436619719    \n",
    " 0.8873239436619719    \n",
    " 0.9154929577464789    \n",
    " 0.9154929577464789    \n",
    " 0.8873239436619719    \n",
    " 0.8169014084507042                 </td><td>0.5876865671641791   \n",
    " 0.5876865671641791   \n",
    " 0.45774647887323944   \n",
    " 0.45774647887323944   \n",
    " 0.45652173913043476  <br> \n",
    " 0.453125                 <br> </td><td>0.5602564102564103    \n",
    " 0.5602564102564103   <br> \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4846153846153846    \n",
    " 0.4461538461538462               </td><td>0.5696969696969697    \n",
    " 0.5696969696969697    \n",
    " 0.4779411764705882    \n",
    " 0.4779411764705882    \n",
    " 0.47014925373134325    \n",
    " 0.4496124031007752           </td></tr>\n",
    "<tr><td>_community_governance      </td><td style=\"text-align: right;\">       29</td><td>Decsision Tree    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.8450704225352113    \n",
    " 0.8591549295774648    \n",
    " 0.8450704225352113    \n",
    " 0.8732394366197183    \n",
    " 0.8591549295774648    \n",
    " 0.8450704225352113                 </td><td>0.6398809523809523   \n",
    " 0.6078431372549019   \n",
    " 0.5652985074626866   \n",
    " 0.43661971830985913   \n",
    " 0.4357142857142857   \n",
    " 0.43478260869565216                  </td><td>0.6263440860215054    \n",
    " 0.5394265232974911    \n",
    " 0.5313620071684588  <br>  \n",
    " 0.5    <br>\n",
    " 0.49193548387096775    \n",
    " 0.4838709677419355               </td><td>0.6324705882352941    \n",
    " 0.5448717948717948    \n",
    " 0.5342874180083482    \n",
    " 0.46616541353383456    \n",
    " 0.4621212121212121    \n",
    " 0.45801526717557256           </td></tr>\n",
    "<tr><td>_cooperative               </td><td style=\"text-align: right;\">        3</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>   </td></tr>\n",
    "<tr><td>_co_management             </td><td style=\"text-align: right;\">       22</td><td>AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes              </td><td>0.9014084507042254    \n",
    " 0.8732394366197183    \n",
    " 0.9154929577464789    \n",
    " 0.9154929577464789    \n",
    " 0.8309859154929577    \n",
    " 0.8169014084507042                 </td><td>0.6299019607843137   \n",
    " 0.5621212121212121   \n",
    " 0.45774647887323944   \n",
    " 0.45774647887323944   \n",
    " 0.45384615384615384   \n",
    " 0.453125                  </td><td>0.5679487179487179    \n",
    " 0.5525641025641026    \n",
    " 0.5    \n",
    " 0.5    \n",
    " 0.45384615384615384    \n",
    " 0.4461538461538462               </td><td>0.5847953216374269    \n",
    " 0.556557945870923    \n",
    " 0.4779411764705882    \n",
    " 0.4779411764705882    \n",
    " 0.4538461538461538    \n",
    " 0.4496124031007752           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Law regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'law_regulation', 'laws_policy_plan_formulation',\n",
       "       'standards_labeling_guideline', 'laws_enforcement_regulation',\n",
       "       'pollution_control', 'surveillance_compliance',\n",
       "       'land_rights_and_tenure_security', 'conflict_resolution'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/law_regulation.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'law_regulation'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['laws_policy_plan_formulation',\n",
    "       'standards_labeling_guideline', 'laws_enforcement_regulation',\n",
    "       'pollution_control', 'surveillance_compliance',\n",
    "       'land_rights_and_tenure_security', 'conflict_resolution']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                       </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>laws_policy_plan_formulation   </td><td style=\"text-align: right;\">      216</td><td>AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest              </td><td>0.9722222222222222    \n",
    " 0.9722222222222222    \n",
    " 0.9305555555555556    \n",
    " 0.9027777777777778    \n",
    " 0.9583333333333334    \n",
    " 0.9444444444444444                 </td><td>0.9857142857142858   \n",
    " 0.9857142857142858   \n",
    " 0.7222222222222222   \n",
    " 0.6818181818181819   \n",
    " 0.9788732394366197   \n",
    " 0.4722222222222222                  </td><td>0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.9632352941176471    \n",
    " 0.9485294117647058    \n",
    " 0.625    <br>\n",
    " 0.5          <br>     </td><td>0.826086956521739    \n",
    " 0.826086956521739    \n",
    " 0.7886083382266589    \n",
    " 0.7395348837209303    \n",
    " 0.6892086330935252    \n",
    " 0.4857142857142857           </td></tr>\n",
    "<tr><td>standards_labeling_guideline   </td><td style=\"text-align: right;\">       42</td><td>Random Forest    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree              </td><td>0.9305555555555556    \n",
    " 0.8472222222222222    \n",
    " 0.8888888888888888    \n",
    " 0.7222222222222222    \n",
    " 0.8472222222222222    \n",
    " 0.7361111111111112                 </td><td>0.7214285714285714   \n",
    " 0.5758064516129032   \n",
    " 0.5701492537313433   \n",
    " 0.5767524401064774   \n",
    " 0.53125   <br>\n",
    " 0.45689655172413796                  </td><td>0.5925373134328358    \n",
    " 0.6402985074626866    \n",
    " 0.5701492537313433    \n",
    " 0.7582089552238807    \n",
    " 0.5477611940298508    \n",
    " 0.39552238805970147               </td><td>0.6246089676746611    \n",
    " 0.5906976744186047    \n",
    " 0.5701492537313433    \n",
    " 0.5566502463054186    \n",
    " 0.5349383440986495   <br> \n",
    " 0.424           </td></tr>\n",
    "<tr><td>laws_enforcement_regulation    </td><td style=\"text-align: right;\">       52</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Random Forest              </td><td>0.8611111111111112    \n",
    " 0.8055555555555556    \n",
    " 0.8333333333333334    \n",
    " 0.8194444444444444    \n",
    " 0.8055555555555556    \n",
    " 0.8055555555555556                 </td><td>0.873015873015873   \n",
    " 0.7304812834224599   \n",
    " 0.8095238095238095 <br>  \n",
    " 0.7890625   <br>\n",
    " 0.7648351648351648   \n",
    " 0.8985507246376812                  </td><td>0.7262032085561497    \n",
    " 0.7304812834224599    \n",
    " 0.6877005347593583    \n",
    " 0.658288770053476    \n",
    " 0.6288770053475936    \n",
    " 0.5882352941176471               </td><td>0.7653194263363754    \n",
    " 0.7304812834224599    \n",
    " 0.7183833116036507    \n",
    " 0.6853781512605042    \n",
    " 0.65    \n",
    " 0.5935483870967742           </td></tr>\n",
    "<tr><td>pollution_control              </td><td style=\"text-align: right;\">       14</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree              </td><td>0.9861111111111112    \n",
    " 0.9722222222222222    \n",
    " 0.9583333333333334    \n",
    " 0.9722222222222222    \n",
    " 0.9583333333333334    \n",
    " 0.9444444444444444                 </td><td>0.8333333333333333  <br> \n",
    " 0.75   <br>\n",
    " 0.6594202898550725   \n",
    " 0.4861111111111111   \n",
    " 0.4859154929577465   \n",
    " 0.4857142857142857                  </td><td>0.9928571428571429    \n",
    " 0.9857142857142858    \n",
    " 0.7357142857142858 <br>   \n",
    " 0.5    <br>\n",
    " 0.4928571428571429    \n",
    " 0.4857142857142857               </td><td>0.8964028776978418    \n",
    " 0.826086956521739    \n",
    " 0.6892086330935252    \n",
    " 0.4929577464788732    \n",
    " 0.4893617021276596    \n",
    " 0.4857142857142857           </td></tr>\n",
    "<tr><td>surveillance_compliance        </td><td style=\"text-align: right;\">       10</td><td>Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree              </td><td>0.9861111111111112    \n",
    " 0.9861111111111112    \n",
    " 0.9722222222222222    \n",
    " 0.9583333333333334    \n",
    " 0.9722222222222222    \n",
    " 0.9583333333333334                 </td><td>0.9929577464788732   \n",
    " 0.9929577464788732   \n",
    " 0.7428571428571429   \n",
    " 0.6594202898550725   \n",
    " 0.4861111111111111   \n",
    " 0.4859154929577465                  </td><td>0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.7428571428571429    \n",
    " 0.7357142857142858    <br>\n",
    " 0.5    <br>\n",
    " 0.4928571428571429               </td><td>0.8297872340425532    \n",
    " 0.8297872340425532    \n",
    " 0.7428571428571429    \n",
    " 0.6892086330935252    \n",
    " 0.4929577464788732    \n",
    " 0.4893617021276596           </td></tr>\n",
    "<tr><td>land_rights_and_tenure_security</td><td style=\"text-align: right;\">        0</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>   </td></tr>\n",
    "<tr><td>conflict_resolution            </td><td style=\"text-align: right;\">        5</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9722222222222222    \n",
    " 0.9722222222222222    \n",
    " 0.9722222222222222    \n",
    " 0.9722222222222222    \n",
    " 0.9722222222222222    \n",
    " 0.9583333333333334                 </td><td>0.4861111111111111   \n",
    " 0.4861111111111111   \n",
    " 0.4861111111111111   \n",
    " 0.4861111111111111   \n",
    " 0.4861111111111111   \n",
    " 0.4859154929577465                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4928571428571429               </td><td>0.4929577464788732    \n",
    " 0.4929577464788732    \n",
    " 0.4929577464788732    \n",
    " 0.4929577464788732    \n",
    " 0.4929577464788732    \n",
    " 0.4893617021276596           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Management_Operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'management_operation', 'ecosystem_based_management',\n",
       "       'sustainable_land_management',\n",
       "       'ecosystem_and_ecosystem_services_conservation_restoration',\n",
       "       'conserved_areas_protected_areas_management',\n",
       "       'wildlife_and_habitat_conservation', 'invasive_and_alien_species_ias',\n",
       "       'integrated_water_resource_management',\n",
       "       'integrated_river_basin_management', 'marine_spatial_planning',\n",
       "       'integrated_coastal_zone_management', 'waste_management',\n",
       "       'wastewater_management', 'demonstration_sites_pilot',\n",
       "       'preservation_of_indigenous_traditional_knowledge',\n",
       "       'species_and_genetic_diversity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Management_Operation.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'management_operation'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['ecosystem_based_management',\n",
    "       'sustainable_land_management',\n",
    "       'ecosystem_and_ecosystem_services_conservation_restoration',\n",
    "       'conserved_areas_protected_areas_management',\n",
    "       'wildlife_and_habitat_conservation', 'invasive_and_alien_species_ias',\n",
    "       'integrated_water_resource_management',\n",
    "       'integrated_river_basin_management', 'marine_spatial_planning',\n",
    "       'integrated_coastal_zone_management', 'waste_management',\n",
    "       'wastewater_management', 'demonstration_sites_pilot',\n",
    "       'preservation_of_indigenous_traditional_knowledge',\n",
    "       'species_and_genetic_diversity']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                                                 </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>ecosystem_based_management                               </td><td style=\"text-align: right;\">       56</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.8076923076923077    \n",
    " 0.7564102564102564    \n",
    " 0.782051282051282    \n",
    " 0.8461538461538461    \n",
    " 0.7307692307692307    \n",
    " 0.7051282051282052                 </td><td>0.6497584541062802   \n",
    " 0.5952380952380952   \n",
    " 0.6071913161465401   \n",
    " 0.9210526315789473   \n",
    " 0.573288331726133   \n",
    " 0.5356798457087754                  </td><td>0.6037946428571428    \n",
    " 0.6004464285714286    \n",
    " 0.5881696428571428    \n",
    " 0.5714285714285714    \n",
    " 0.5848214285714286    \n",
    " 0.5412946428571428               </td><td>0.6175220660346519    \n",
    " 0.597610643497149    \n",
    " 0.5951145038167939    \n",
    " 0.5821428571428571    \n",
    " 0.577290322580645    \n",
    " 0.5370322580645162           </td></tr>\n",
    "<tr><td>sustainable_land_management                              </td><td style=\"text-align: right;\">      115</td><td>Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.7051282051282052    \n",
    " 0.6923076923076923    \n",
    " 0.6794871794871795    \n",
    " 0.6666666666666666    \n",
    " 0.6410256410256411    \n",
    " 0.6025641025641025                 </td><td>0.7150197628458498   <br>\n",
    " 0.6875   <br>\n",
    " 0.6939393939393939   \n",
    " 0.6603260869565217   \n",
    " 0.6333333333333333   \n",
    " 0.5933424845573095                  </td><td>0.6818181818181819    \n",
    " 0.6804812834224598    \n",
    " 0.6925133689839572    \n",
    " 0.6577540106951871    \n",
    " 0.6283422459893049    \n",
    " 0.5909090909090908               </td><td>0.6820839978734715    \n",
    " 0.6820652173913044    \n",
    " 0.6794344895610718    \n",
    " 0.6585858585858586    \n",
    " 0.6290760869565217    \n",
    " 0.5912087912087912           </td></tr>\n",
    "<tr><td>ecosystem_and_ecosystem_services_conservation_restoration</td><td style=\"text-align: right;\">       70</td><td>K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent              </td><td>0.7564102564102564    \n",
    " 0.6666666666666666    \n",
    " 0.8076923076923077    \n",
    " 0.6666666666666666    \n",
    " 0.717948717948718    \n",
    " 0.6025641025641025                 </td><td>0.6174242424242424   \n",
    " 0.5612648221343874   \n",
    " 0.9013157894736843   \n",
    " 0.5298840321141838   \n",
    " 0.5318860244233379 <br>  \n",
    " 0.525                  </td><td>0.5896817743490839    \n",
    " 0.5747348119575699    \n",
    " 0.5588235294117647    \n",
    " 0.532304725168756    \n",
    " 0.5226615236258437    \n",
    " 0.5337512054001928               </td><td>0.5976106434971491    \n",
    " 0.5629310344827586    \n",
    " 0.5505186323472916    \n",
    " 0.5305555555555556    \n",
    " 0.5212053571428571    \n",
    " 0.5159159159159159           </td></tr>\n",
    "<tr><td>conserved_areas_protected_areas_management               </td><td style=\"text-align: right;\">       77</td><td>Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " Random Forest              </td><td>0.8461538461538461    \n",
    " 0.782051282051282    \n",
    " 0.7564102564102564    \n",
    " 0.7435897435897436    \n",
    " 0.6666666666666666    \n",
    " 0.7564102564102564                 </td><td>0.7982758620689655   \n",
    " 0.7155388471177945   \n",
    " 0.7004357298474946   \n",
    " 0.6696428571428572   \n",
    " 0.6064285714285714   \n",
    " 0.6690821256038648                  </td><td>0.7982758620689655    \n",
    " 0.7224137931034482    \n",
    " 0.7379310344827585    \n",
    " 0.6801724137931034    \n",
    " 0.628448275862069    \n",
    " 0.5905172413793103               </td><td>0.7982758620689655    \n",
    " 0.7187698833510074    \n",
    " 0.7107163771227796    \n",
    " 0.6741854636591478    \n",
    " 0.6087962962962963    \n",
    " 0.5976106434971491           </td></tr>\n",
    "<tr><td>wildlife_and_habitat_conservation                        </td><td style=\"text-align: right;\">       44</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Stochastic Gradient Descent              </td><td>0.8205128205128205    \n",
    " 0.8076923076923077    \n",
    " 0.782051282051282    \n",
    " 0.782051282051282    \n",
    " 0.8333333333333334    \n",
    " 0.8076923076923077                 </td><td>0.6838235294117647   \n",
    " 0.6601085481682496   \n",
    " 0.6071913161465401   \n",
    " 0.6071913161465401   \n",
    " 0.7533333333333333   \n",
    " 0.6178082191780823                  </td><td>0.6395089285714286    \n",
    " 0.6316964285714286    \n",
    " 0.5881696428571428    \n",
    " 0.5881696428571428    \n",
    " 0.5636160714285714    \n",
    " 0.5479910714285714               </td><td>0.6553030303030303    \n",
    " 0.6427480916030535    \n",
    " 0.5951145038167939    \n",
    " 0.5951145038167939    \n",
    " 0.5708844688954718    \n",
    " 0.5505186323472916           </td></tr>\n",
    "<tr><td>invasive_and_alien_species_ias                           </td><td style=\"text-align: right;\">        9</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor              </td><td>0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9487179487179487    \n",
    " 0.9487179487179487    \n",
    " 0.9487179487179487                 </td><td>0.8682432432432432   \n",
    " 0.986842105263158   \n",
    " 0.986842105263158   \n",
    " 0.47435897435897434   \n",
    " 0.47435897435897434   \n",
    " 0.47435897435897434                  </td><td>0.8682432432432432    <br>\n",
    " 0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.8682432432432432    \n",
    " 0.8266666666666667    \n",
    " 0.8266666666666667    \n",
    " 0.4868421052631579    \n",
    " 0.4868421052631579    \n",
    " 0.4868421052631579           </td></tr>\n",
    "<tr><td>integrated_water_resource_management                     </td><td style=\"text-align: right;\">       15</td><td>Random Forest    \n",
    " AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Decsision Tree              </td><td>0.9871794871794872    \n",
    " 0.9743589743589743    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9102564102564102    \n",
    " 0.8717948717948718                 </td><td>0.4935897435897436   \n",
    " 0.4935064935064935   \n",
    " 0.4934210526315789   \n",
    " 0.4934210526315789   \n",
    " 0.4930555555555556   \n",
    " 0.4927536231884058                  </td><td>0.5  <br>  \n",
    " 0.4935064935064935    \n",
    " 0.487012987012987    \n",
    " 0.487012987012987    \n",
    " 0.461038961038961    \n",
    " 0.44155844155844154               </td><td>0.4967741935483871    \n",
    " 0.4935064935064935    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.476510067114094    \n",
    " 0.4657534246575342           </td></tr>\n",
    "<tr><td>integrated_river_basin_management                        </td><td style=\"text-align: right;\">        7</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9615384615384616                 </td><td>0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.487012987012987                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4934210526315789               </td><td>0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49019607843137253           </td></tr>\n",
    "<tr><td>marine_spatial_planning                                  </td><td style=\"text-align: right;\">        4</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9615384615384616                 </td><td>0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.487012987012987                  </td><td>0.5   <br> \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4934210526315789               </td><td>0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49019607843137253           </td></tr>\n",
    "<tr><td>integrated_coastal_zone_management                       </td><td style=\"text-align: right;\">       22</td><td>Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor              </td><td>0.8846153846153846    \n",
    " 0.9230769230769231    \n",
    " 0.8974358974358975    \n",
    " 0.9230769230769231    \n",
    " 0.9230769230769231    \n",
    " 0.9102564102564102                 </td><td>0.6146881287726358   \n",
    " 0.7171052631578947   \n",
    " 0.5912162162162162   \n",
    " 0.46153846153846156   \n",
    " 0.46153846153846156   \n",
    " 0.461038961038961                  </td><td>0.6319444444444444    \n",
    " 0.576388888888889  <br>  \n",
    " 0.5625    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4930555555555556               </td><td>0.6223776223776224    \n",
    " 0.6047297297297298    \n",
    " 0.5726027397260274    \n",
    " 0.48000000000000004    \n",
    " 0.48000000000000004    \n",
    " 0.476510067114094           </td></tr>\n",
    "<tr><td>waste_management                                         </td><td style=\"text-align: right;\">       32</td><td>Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest              </td><td>0.9487179487179487    \n",
    " 0.9230769230769231    \n",
    " 0.9230769230769231    \n",
    " 0.9102564102564102    \n",
    " 0.8974358974358975    \n",
    " 0.8717948717948718                 </td><td>0.9227053140096618   \n",
    " 0.841248303934871   \n",
    " 0.8933601609657947   \n",
    " 0.8392857142857143   \n",
    " 0.8520547945205479   \n",
    " 0.7733333333333333                  </td><td>0.8561736770691994    \n",
    " 0.841248303934871    \n",
    " 0.7652645861601085    \n",
    " 0.7578018995929443    \n",
    " 0.6743554952510176    \n",
    " 0.5834464043419267               </td><td>0.8852941176470588    \n",
    " 0.841248303934871    \n",
    " 0.8115942028985507    \n",
    " 0.790242028428736    \n",
    " 0.7214285714285715    \n",
    " 0.607645875251509           </td></tr>\n",
    "<tr><td>wastewater_management                                    </td><td style=\"text-align: right;\">        4</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616    \n",
    " 0.9615384615384616                 </td><td>0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308   \n",
    " 0.4807692307692308                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253    \n",
    " 0.49019607843137253           </td></tr>\n",
    "<tr><td>demonstration_sites_pilot                                </td><td style=\"text-align: right;\">       23</td><td>Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost              </td><td>0.9102564102564102    \n",
    " 0.9230769230769231    \n",
    " 0.8846153846153846    \n",
    " 0.8974358974358975    \n",
    " 0.8974358974358975    \n",
    " 0.8589743589743589                 </td><td>0.7575452716297786   \n",
    " 0.9605263157894737   \n",
    " 0.6790744466800804   \n",
    " 0.7039473684210527   \n",
    " 0.44871794871794873   \n",
    " 0.44666666666666666                  </td><td>0.7285714285714286 <br>   \n",
    " 0.625    <br>\n",
    " 0.6589285714285714    \n",
    " 0.5553571428571429    \n",
    " 0.5    <br>\n",
    " 0.4785714285714286               </td><td>0.7418439716312056    \n",
    " 0.6794520547945205    \n",
    " 0.6680851063829787    \n",
    " 0.5726027397260274    \n",
    " 0.472972972972973    \n",
    " 0.4620689655172414           </td></tr>\n",
    "<tr><td>preservation_of_indigenous_traditional_knowledge         </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9871794871794872    \n",
    " 0.9871794871794872                 </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5   <br>\n",
    " 0.5       <br>           </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4935897435897436    \n",
    " 0.4935897435897436               </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4967741935483871    \n",
    " 0.4967741935483871           </td></tr>\n",
    "<tr><td>species_and_genetic_diversity                            </td><td style=\"text-align: right;\">        4</td><td>Decsision Tree    \n",
    " AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743    \n",
    " 0.9743589743589743                 </td><td>0.743421052631579   \n",
    " 0.743421052631579   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717   \n",
    " 0.48717948717948717                  </td><td>0.743421052631579    \n",
    " 0.743421052631579 <br>    \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.743421052631579    \n",
    " 0.743421052631579    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345    \n",
    " 0.49350649350649345           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mitigation_adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'mitigation_adaptation', 'species_adaptation',\n",
       "       'ecosystem_mitigation_and_adaptation',\n",
       "       'drought_mitigation_early_warning', 'flood_prevention_early_warning',\n",
       "       'sustainable_fire_management', 'erosion_prevention',\n",
       "       'coastal_risk_reduction', 'sea_level_rise',\n",
       "       'infrastructure_against_natural_hazards', 'storm_mitigation',\n",
       "       'blue_carbon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Mitigation_Adaptation.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'mitigation_adaptation'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['species_adaptation',\n",
    "       'ecosystem_mitigation_and_adaptation',\n",
    "       'drought_mitigation_early_warning', 'flood_prevention_early_warning',\n",
    "       'sustainable_fire_management', 'erosion_prevention',\n",
    "       'coastal_risk_reduction', 'sea_level_rise',\n",
    "       'infrastructure_against_natural_hazards', 'storm_mitigation',\n",
    "       'blue_carbon']\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                              </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>species_adaptation                    </td><td style=\"text-align: right;\">        3</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286                 </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5   <br>\n",
    " 0.5       <br>           </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4642857142857143    \n",
    " 0.4642857142857143               </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815           </td></tr>\n",
    "<tr><td>ecosystem_mitigation_and_adaptation   </td><td style=\"text-align: right;\">       23</td><td>K Nearest Neighbor    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Random Forest              </td><td>0.7857142857142857    \n",
    " 0.7142857142857143    \n",
    " 0.6428571428571429    \n",
    " 0.6428571428571429    \n",
    " 0.42857142857142855    \n",
    " 0.35714285714285715                 </td><td>0.775  <br> \n",
    " 0.7142857142857142  <br> \n",
    " 0.625   <br>\n",
    " 0.625   <br>\n",
    " 0.42857142857142855   \n",
    " 0.41666666666666663                  </td><td>0.7444444444444445    \n",
    " 0.7333333333333334    \n",
    " 0.6333333333333333    \n",
    " 0.6333333333333333    \n",
    " 0.4222222222222222    \n",
    " 0.4555555555555556               </td><td>0.7543859649122806    \n",
    " 0.7083333333333333    \n",
    " 0.625668449197861    \n",
    " 0.625668449197861    \n",
    " 0.41666666666666663    \n",
    " 0.3262032085561497           </td></tr>\n",
    "<tr><td>drought_mitigation_early_warning      </td><td style=\"text-align: right;\">        6</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.5714285714285714 <br>   \n",
    " 0.5                 </td><td>0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.36363636363636365 <br>  \n",
    " 0.35                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.36363636363636365    \n",
    " 0.3181818181818182               </td><td>0.44   <br> \n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.36363636363636365    \n",
    " 0.3333333333333333           </td></tr>\n",
    "<tr><td>flood_prevention_early_warning        </td><td style=\"text-align: right;\">       16</td><td>Decsision Tree    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " AdaBoost    \n",
    " Random Forest              </td><td>0.6428571428571429    \n",
    " 0.6428571428571429    \n",
    " 0.6428571428571429    \n",
    " 0.7142857142857143    \n",
    " 0.5714285714285714    \n",
    " 0.6428571428571429                 </td><td>0.6  <br> \n",
    " 0.6   <br>\n",
    " 0.6   <br>\n",
    " 0.8461538461538461   \n",
    " 0.48484848484848486   \n",
    " 0.32142857142857145                  </td><td>0.5888888888888889    \n",
    " 0.5888888888888889    \n",
    " 0.5888888888888889    <br>\n",
    " 0.6    <br>\n",
    " 0.48888888888888893  <br>  \n",
    " 0.5               </td><td>0.5906432748538011    \n",
    " 0.5906432748538011    \n",
    " 0.5906432748538011    \n",
    " 0.5757575757575757    \n",
    " 0.47500000000000003    \n",
    " 0.391304347826087           </td></tr>\n",
    "<tr><td>sustainable_fire_management           </td><td style=\"text-align: right;\">        4</td><td>Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.8571428571428571    \n",
    " 0.8571428571428571    \n",
    " 0.8571428571428571                 </td><td>0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.46153846153846156   \n",
    " 0.46153846153846156   \n",
    " 0.46153846153846156                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.46153846153846156    \n",
    " 0.46153846153846156    \n",
    " 0.46153846153846156               </td><td>0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.46153846153846156    \n",
    " 0.46153846153846156    \n",
    " 0.46153846153846156           </td></tr>\n",
    "<tr><td>erosion_prevention                    </td><td style=\"text-align: right;\">        8</td><td>Decsision Tree    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest              </td><td>0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.8571428571428571    \n",
    " 0.8571428571428571    \n",
    " 0.7142857142857143                 </td><td>0.9545454545454546   \n",
    " 0.9545454545454546   \n",
    " 0.9545454545454546   \n",
    " 0.9166666666666667   \n",
    " 0.9166666666666667   \n",
    " 0.35714285714285715                  </td><td>0.875   <br> \n",
    " 0.875    <br>\n",
    " 0.875    <br>\n",
    " 0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.5         <br>      </td><td>0.9047619047619047    \n",
    " 0.9047619047619047    \n",
    " 0.9047619047619047    \n",
    " 0.7878787878787878    \n",
    " 0.7878787878787878    \n",
    " 0.41666666666666663           </td></tr>\n",
    "<tr><td>coastal_risk_reduction                </td><td style=\"text-align: right;\">       11</td><td>Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes              </td><td>0.5714285714285714    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7142857142857143    \n",
    " 0.7142857142857143                 </td><td>0.5714285714285714   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.38461538461538464   \n",
    " 0.38461538461538464                  </td><td>0.606060606060606   <br> \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.45454545454545453    \n",
    " 0.45454545454545453               </td><td>0.5333333333333332   <br> \n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.41666666666666663    \n",
    " 0.41666666666666663           </td></tr>\n",
    "<tr><td>sea_level_rise                        </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286                 </td><td>0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143                  </td><td>0.5   <br> \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815           </td></tr>\n",
    "<tr><td>infrastructure_against_natural_hazards</td><td style=\"text-align: right;\">        7</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857    \n",
    " 0.7857142857142857                 </td><td>0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285   \n",
    " 0.39285714285714285                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.44  <br>  \n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.44    <br>\n",
    " 0.44        <br>   </td></tr>\n",
    "<tr><td>storm_mitigation                      </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286    \n",
    " 0.9285714285714286                 </td><td>0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143   \n",
    " 0.4642857142857143                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815    \n",
    " 0.4814814814814815           </td></tr>\n",
    "<tr><td>blue_carbon                           </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0  <br> \n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>       </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>   </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# monitor_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'monitor_inventory', 'data_quality', 'impact_assessment',\n",
       "       'waste_pollutants_monitoring', 'water_quality_quantity',\n",
       "       'ecological_monitoring', 'spatial_monitoring_analysis',\n",
       "       'ecosystem_services_monitoring', 'management_effectiveness_mett',\n",
       "       'accounting', 'knowledge_data_management'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Monitor_Inventory.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'monitor_inventory'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['data_quality', 'impact_assessment',\n",
    "       'waste_pollutants_monitoring', 'water_quality_quantity',\n",
    "       'ecological_monitoring', 'spatial_monitoring_analysis',\n",
    "       'ecosystem_services_monitoring', 'management_effectiveness_mett',\n",
    "       'accounting', 'knowledge_data_management']\n",
    "\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                     </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>data_quality                 </td><td style=\"text-align: right;\">       22</td><td>Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.8367346938775511    \n",
    " 0.7346938775510204    \n",
    " 0.8775510204081632    \n",
    " 0.8775510204081632    \n",
    " 0.8571428571428571    \n",
    " 0.7959183673469388                 </td><td>0.6201550387596899   \n",
    " 0.5737179487179487   \n",
    " 0.4387755102040816   \n",
    " 0.4387755102040816 <br>   \n",
    " 0.4375   <br>\n",
    " 0.43333333333333335                  </td><td>0.6201550387596899    \n",
    " 0.6337209302325582  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4883720930232558    \n",
    " 0.45348837209302323               </td><td>0.6201550387596899    \n",
    " 0.5756162558294471    \n",
    " 0.4673913043478261    \n",
    " 0.4673913043478261    \n",
    " 0.4615384615384615    \n",
    " 0.4431818181818182           </td></tr>\n",
    "<tr><td>impact_assessment            </td><td style=\"text-align: right;\">       41</td><td>Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor              </td><td>0.5510204081632653    \n",
    " 0.5918367346938775    \n",
    " 0.6326530612244898    \n",
    " 0.7755102040816326    \n",
    " 0.6326530612244898    \n",
    " 0.7346938775510204                 </td><td>0.5119047619047619   \n",
    " 0.48235294117647054   \n",
    " 0.47248803827751196   \n",
    " 0.3877551020408163   \n",
    " 0.4305555555555556   \n",
    " 0.3829787234042553                  </td><td>0.5167464114832536    \n",
    " 0.4784688995215311    \n",
    " 0.47248803827751196    <br>\n",
    " 0.5    <br>\n",
    " 0.44019138755980863    \n",
    " 0.47368421052631576               </td><td>0.48958333333333337    \n",
    " 0.47649572649572647    \n",
    " 0.47248803827751196    \n",
    " 0.43678160919540227    \n",
    " 0.43461538461538457    \n",
    " 0.4235294117647058           </td></tr>\n",
    "<tr><td>waste_pollutants_monitoring  </td><td style=\"text-align: right;\">        9</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0               </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>       </td></tr>\n",
    "<tr><td>water_quality_quantity       </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939                 </td><td>0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423           </td></tr>\n",
    "<tr><td>ecological_monitoring        </td><td style=\"text-align: right;\">        9</td><td>K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent              </td><td>0.9795918367346939    \n",
    " 0.9591836734693877    \n",
    " 0.9591836734693877    \n",
    " 0.9591836734693877    \n",
    " 0.9387755102040817    \n",
    " 0.9183673469387755                 </td><td>0.9895833333333333   <br>\n",
    " 0.75   <br>\n",
    " 0.7393617021276595   \n",
    " 0.47959183673469385   \n",
    " 0.4791666666666667   \n",
    " 0.4787234042553192                  </td><td>0.75  <br>  \n",
    " 0.9787234042553192    \n",
    " 0.7393617021276595    <br>\n",
    " 0.5    <br>\n",
    " 0.48936170212765956    \n",
    " 0.4787234042553192               </td><td>0.8280701754385965    \n",
    " 0.822463768115942    \n",
    " 0.7393617021276595    \n",
    " 0.4895833333333333    \n",
    " 0.4842105263157895    \n",
    " 0.47872340425531923           </td></tr>\n",
    "<tr><td>spatial_monitoring_analysis  </td><td style=\"text-align: right;\">        5</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9795918367346939    \n",
    " 0.9591836734693877                 </td><td>0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4897959183673469   \n",
    " 0.4895833333333333                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4895833333333333               </td><td>0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4948453608247423    \n",
    " 0.4895833333333333           </td></tr>\n",
    "<tr><td>ecosystem_services_monitoring</td><td style=\"text-align: right;\">        4</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9183673469387755                 </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5       <br>           </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.45918367346938777               </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4787234042553192           </td></tr>\n",
    "<tr><td>management_effectiveness_mett</td><td style=\"text-align: right;\">        2</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>1.0   <br> \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.9591836734693877    \n",
    " 0.9591836734693877                 </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 0.5   <br>\n",
    " 0.5       <br>           </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.47959183673469385    \n",
    " 0.47959183673469385               </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.4895833333333333    \n",
    " 0.4895833333333333           </td></tr>\n",
    "<tr><td>accounting                   </td><td style=\"text-align: right;\">       54</td><td>Stochastic Gradient Descent    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes              </td><td>0.9387755102040817    \n",
    " 0.9183673469387755    \n",
    " 0.9183673469387755    \n",
    " 0.8979591836734694    \n",
    " 0.8775510204081632    \n",
    " 0.8163265306122449                 </td><td>0.9372549019607843   <br>\n",
    " 0.9   <br>\n",
    " 0.9459459459459459   \n",
    " 0.9342105263157895   \n",
    " 0.8714285714285714   \n",
    " 0.8068561872909699                  </td><td>0.9223484848484849    \n",
    " 0.9393939393939394 <br>   \n",
    " 0.875    <br>\n",
    " 0.84375    <br>\n",
    " 0.8446969696969697    \n",
    " 0.8475378787878788               </td><td>0.929224843524314    \n",
    " 0.9121863799283154    \n",
    " 0.8999999999999999    \n",
    " 0.8721961398017736    \n",
    " 0.8558823529411764    \n",
    " 0.8083441981747067           </td></tr>\n",
    "<tr><td>knowledge_data_management    </td><td style=\"text-align: right;\">      117</td><td>Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Random Forest    \n",
    " AdaBoost              </td><td>0.6938775510204082    \n",
    " 0.6326530612244898    \n",
    " 0.5510204081632653    \n",
    " 0.6326530612244898    \n",
    " 0.6938775510204082    \n",
    " 0.6122448979591837                 </td><td>0.6217948717948718   \n",
    " 0.5808823529411764   \n",
    " 0.4908088235294118   \n",
    " 0.4880952380952381   \n",
    " 0.3469387755102041   \n",
    " 0.3333333333333333                  </td><td>0.5931372549019608    \n",
    " 0.5862745098039216    \n",
    " 0.4901960784313726    \n",
    " 0.49313725490196075 <br>   \n",
    " 0.5    \n",
    " 0.4411764705882353               </td><td>0.5972602739726027    \n",
    " 0.5823863636363635    \n",
    " 0.48958333333333337    \n",
    " 0.47248803827751207    \n",
    " 0.4096385542168675    \n",
    " 0.37974683544303794           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# technology_innovation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy',\n",
       "       'technology_innovation', 'transition_to_safer_alternatives',\n",
       "       'cooling_energy_efficiency', 'alternative_energy_sources',\n",
       "       'urban_green_space', 'green_building_practices',\n",
       "       'biochar_soil_amendment', 'clearing_house_mechanism',\n",
       "       'improved_soil_and_water_management_techniques',\n",
       "       'water_supply_and_sanitation', 'infrastructure_building',\n",
       "       'best_available_techniques_best_environmental_practices_bat_bep',\n",
       "       'innovations_in_techniques_approaches'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('../data/processed/encoded_labels/Technology_Innovation.xlsx')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = df.drop(['Unnamed: 0', 'PIMS_ID', 'all_text_clean', 'all_text_clean_spacy', 'technology_innovation'], axis=1)\n",
    "counts = []\n",
    "categories = list(df_labels.columns.values)\n",
    "for i in categories:\n",
    "    counts.append((i, df_labels[i].sum()))\n",
    "df_stats = pd.DataFrame(counts, columns=['category', 'number_of_inputs'])\n",
    "\n",
    "categories = ['transition_to_safer_alternatives',\n",
    "       'cooling_energy_efficiency', 'alternative_energy_sources',\n",
    "       'urban_green_space', 'green_building_practices',\n",
    "       'biochar_soil_amendment', 'clearing_house_mechanism',\n",
    "       'improved_soil_and_water_management_techniques',\n",
    "       'water_supply_and_sanitation', 'infrastructure_building',\n",
    "       'best_available_techniques_best_environmental_practices_bat_bep',\n",
    "       'innovations_in_techniques_approaches']\n",
    "\n",
    "\n",
    "\n",
    "#Creating the features (tf-idf weights) for the processed text\n",
    "texts = df['all_text_clean'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(texts)\n",
    "\n",
    "#Turning the labels into numbers\n",
    "y = pd.DataFrame(df, columns = categories)\n",
    "#Dimenionality reduction. Only using the 100 best features er category\n",
    "\n",
    "lsa = TruncatedSVD(n_components=100, \n",
    "                   n_iter=10, \n",
    "                   random_state=3)\n",
    "\n",
    "X = lsa.fit_transform(X)\n",
    "#Creating a dict of the models\n",
    "model_dict = {\n",
    "              'Stochastic Gradient Descent' : OneVsRestClassifier(SGDClassifier(random_state=3, loss='log'), n_jobs=1),\n",
    "              'Random Forest': OneVsRestClassifier(RandomForestClassifier(random_state=3), n_jobs=1),\n",
    "              'Decsision Tree': OneVsRestClassifier(DecisionTreeClassifier(random_state=3), n_jobs=1),\n",
    "              'AdaBoost': OneVsRestClassifier(AdaBoostClassifier(random_state=3), n_jobs=1),\n",
    "              'Gaussian Naive Bayes': OneVsRestClassifier(GaussianNB(), n_jobs=1),\n",
    "              'K Nearest Neighbor': OneVsRestClassifier(KNeighborsClassifier(), n_jobs=1)}\n",
    "\n",
    "\n",
    "#Train test split with stratified sampling for evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = .3, \n",
    "                                                    shuffle = True,  \n",
    "                                                    random_state = 3)\n",
    "y_train = y_train.dropna(axis=1)\n",
    "#Function to get the scores for each model in a df\n",
    "def model_score_df(model_dict, X_train, X_test, y_train, y_test):   \n",
    "    model_name, ac_score_list, p_score_list, r_score_list, f1_score_list = [], [], [], [], []\n",
    "    for k,v in model_dict.items():   \n",
    "        model_name.append(k)\n",
    "        v.fit(X_train, y_train)\n",
    "        y_pred = v.predict(X_test)\n",
    "        ac_score_list.append(accuracy_score(y_test, y_pred))\n",
    "        p_score_list.append(precision_score(y_test, y_pred, average='macro'))\n",
    "        r_score_list.append(recall_score(y_test, y_pred, average='macro'))\n",
    "        f1_score_list.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        model_comparison_df = pd.DataFrame([model_name, ac_score_list, p_score_list, r_score_list, f1_score_list]).T\n",
    "        model_comparison_df.columns = ['model_name', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "        model_comparison_df = model_comparison_df.sort_values(by='f1_score', ascending=False)\n",
    "    return model_comparison_df\n",
    "\n",
    "\n",
    "def printTable(myDict, colList=None, sep='\\uFFFA'):\n",
    "    \"\"\" Pretty print a list of dictionaries (myDict) as a dynamically sized table.\n",
    "   If column names (colList) aren't specified, they will show in random order.\n",
    "   sep: row separator. Ex: sep='\\n' on Linux. Default: dummy to not split line.\n",
    "   Author: Thierry Husson - Use it as you want but don't blame me.\n",
    "   \"\"\"\n",
    "    if not colList: colList = list(myDict[0].keys() if myDict else [])\n",
    "    myList = [colList] # 1st row = header\n",
    "    for item in myDict: myList.append([str(item[col] or '') for col in colList])\n",
    "    colSize = [max(map(len,(sep.join(col)).split(sep))) for col in zip(*myList)]\n",
    "    formatStr = ' | '.join([\"{{:<{}}}\".format(i) for i in colSize])\n",
    "    line = formatStr.replace(' | ','-+-').format(*['-' * i for i in colSize])\n",
    "    item=myList.pop(0); lineDone=False\n",
    "    while myList:\n",
    "        if all(not i for i in item):\n",
    "            item=myList.pop(0)\n",
    "            if line and (sep!='\\uFFFA' or not lineDone): print(line); lineDone=True\n",
    "        row = [i.split(sep,1) for i in item]\n",
    "        print(formatStr.format(*[i[0] for i in row]))\n",
    "        item = [i[1] if len(i)>1 else '' for i in row]\n",
    "        \n",
    "\n",
    "from tabulate import tabulate        \n",
    "lis = []\n",
    "for category in categories:\n",
    "    dic = {}\n",
    "    dff = model_score_df(model_dict, X_train, X_test, y_train[category], y_test[category])\n",
    "    # Using DataFrame.insert() to add a column\n",
    "    dic['Category'] = category\n",
    "    dic['#Inputs'] = df_stats.number_of_inputs[df_stats['category'] == category]\n",
    "    dic['Classifiers'] = '    \\n '.join(dff.model_name.apply(str).tolist())\n",
    "    dic['accuracy_score'] = '    \\n '.join(dff.accuracy_score.apply(str).tolist()) \n",
    "    dic['precision_score'] = '   \\n '.join(dff.precision_score.apply(str).tolist())\n",
    "    dic['recall_score'] = '    \\n '.join(dff.recall_score.apply(str).tolist())\n",
    "    dic['f1_score'] = '    \\n '.join(dff.f1_score.apply(str).tolist())\n",
    "    lis.append(dic)\n",
    "    \n",
    "#headers = ['Category', 'Classifiers', 'accuracy_score', 'precision_score', 'recall_score', 'f1_score']\n",
    "#print(tabulate(lis, tablefmt='html'))\n",
    "header = lis[0].keys()\n",
    "rows =  [x.values() for x in lis]\n",
    "\n",
    "#print (tabulate(rows, header, tablefmt='html'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr><th>Category                                                      </th><th style=\"text-align: right;\">  #Inputs</th><th>Classifiers  </th><th>accuracy_score  </th><th>precision_score  </th><th>recall_score  </th><th>f1_score  </th></tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>transition_to_safer_alternatives                              </td><td style=\"text-align: right;\">       13</td><td>Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost              </td><td>0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.8695652173913043    \n",
    " 0.9130434782608695    \n",
    " 0.782608695652174                 </td><td>0.8333333333333333   \n",
    " 0.9772727272727273   \n",
    " 0.9772727272727273  <br> \n",
    " 0.7   <br>\n",
    " 0.7261904761904762   \n",
    " 0.5722222222222222                  </td><td>0.9761904761904762 <br>   \n",
    " 0.75    <br>\n",
    " 0.75    <br>\n",
    " 0.9285714285714286    \n",
    " 0.7261904761904762    \n",
    " 0.6547619047619048               </td><td>0.8878048780487805    \n",
    " 0.8217054263565892    \n",
    " 0.8217054263565892    \n",
    " 0.7472527472527473    \n",
    " 0.7261904761904762    \n",
    " 0.5787545787545788           </td></tr>\n",
    "<tr><td>cooling_energy_efficiency                                     </td><td style=\"text-align: right;\">        3</td><td>Decsision Tree    \n",
    " AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0 <br>    \n",
    " 1.0    <br>\n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348                 </td><td>1.0 <br>  \n",
    " 1.0   <br>\n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174                  </td><td>1.0    <br>\n",
    " 1.0    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5               </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889           </td></tr>\n",
    "<tr><td>alternative_energy_sources                                    </td><td style=\"text-align: right;\">       13</td><td>Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " Random Forest              </td><td>0.9565217391304348    \n",
    " 0.8695652173913043    \n",
    " 0.8695652173913043    \n",
    " 0.782608695652174    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391                 </td><td>0.975  <br> \n",
    " 0.7833333333333333   \n",
    " 0.9318181818181819   \n",
    " 0.6444444444444444   \n",
    " 0.67857142857<br>14286   \n",
    " 0.41304347826086957                  </td><td>0.875   <br> \n",
    " 0.7236842105263157    <br>\n",
    " 0.625    <br>\n",
    " 0.6710526315789473    \n",
    " 0.5986842105263157    \n",
    " 0.5               </td><td>0.9157509157509157    \n",
    " 0.7472527472527473    \n",
    " 0.6634146341463414    \n",
    " 0.6546546546546547    \n",
    " 0.6166666666666667    \n",
    " 0.45238095238095233           </td></tr>\n",
    "<tr><td>urban_green_space                                             </td><td style=\"text-align: right;\">        3</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost              </td><td>0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.8695652173913043                 </td><td>0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.47619047619047616                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.45454545454545453               </td><td>0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.46511627906976744           </td></tr>\n",
    "<tr><td>green_building_practices                                      </td><td style=\"text-align: right;\">        5</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Gaussian Naive Bayes              </td><td>0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9130434782608695    \n",
    " 0.9130434782608695                 </td><td>0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4772727272727273   \n",
    " 0.4772727272727273                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.4772727272727273    \n",
    " 0.4772727272727273               </td><td>0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4772727272727273    \n",
    " 0.4772727272727273           </td></tr>\n",
    "<tr><td>biochar_soil_amendment                                        </td><td style=\"text-align: right;\">        0</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0        <br>         </td><td>1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0   <br>\n",
    " 1.0       <br>           </td><td>1.0  <br>  \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0               </td><td>1.0 <br>   \n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0    <br>\n",
    " 1.0           </td></tr>\n",
    "<tr><td>clearing_house_mechanism                                      </td><td style=\"text-align: right;\">        1</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor              </td><td>0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348    \n",
    " 0.9565217391304348                 </td><td>0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174   \n",
    " 0.4782608695652174                  </td><td>0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889    \n",
    " 0.4888888888888889           </td></tr>\n",
    "<tr><td>improved_soil_and_water_management_techniques                 </td><td style=\"text-align: right;\">       14</td><td>Gaussian Naive Bayes    \n",
    " AdaBoost    \n",
    " Decsision Tree    \n",
    " K Nearest Neighbor    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest              </td><td>0.9130434782608695    \n",
    " 0.8695652173913043    \n",
    " 0.8260869565217391    \n",
    " 0.782608695652174    \n",
    " 0.782608695652174    \n",
    " 0.7391304347826086                 </td><td>0.9473684210526316 <br>  \n",
    " 0.925   <br>\n",
    " 0.9047619047619048   \n",
    " 0.7333333333333334   \n",
    " 0.8863636363636364   \n",
    " 0.3695652173913043                  </td><td>0.8333333333333333    \n",
    " 0.75    \n",
    " 0.6666666666666666    \n",
    " 0.6372549019607843    \n",
    " 0.5833333333333334 <br>   \n",
    " 0.5               </td><td>0.8722222222222222    \n",
    " 0.7927927927927927    \n",
    " 0.6973684210526316    \n",
    " 0.6546546546546546    \n",
    " 0.5787545787545787    <br>\n",
    " 0.425           </td></tr>\n",
    "<tr><td>water_supply_and_sanitation                                   </td><td style=\"text-align: right;\">        8</td><td>Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " AdaBoost    \n",
    " Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree              </td><td>0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.782608695652174                 </td><td>0.41304347826086957   \n",
    " 0.41304347826086957   \n",
    " 0.41304347826086957   \n",
    " 0.41304347826086957   \n",
    " 0.41304347826086957   \n",
    " 0.4090909090909091                  </td><td>0.5  <br>  \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.47368421052631576               </td><td>0.45238095238095233    \n",
    " 0.45238095238095233    \n",
    " 0.45238095238095233    \n",
    " 0.45238095238095233    \n",
    " 0.45238095238095233    \n",
    " 0.43902439024390244           </td></tr>\n",
    "<tr><td>infrastructure_building                                       </td><td style=\"text-align: right;\">       15</td><td>Gaussian Naive Bayes    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " AdaBoost    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest              </td><td>0.8260869565217391    \n",
    " 0.8260869565217391    \n",
    " 0.7391304347826086    \n",
    " 0.6956521739130435    \n",
    " 0.782608695652174    \n",
    " 0.782608695652174                 </td><td>0.7444444444444445   \n",
    " 0.9090909090909092   \n",
    " 0.5666666666666667   \n",
    " 0.5197368421052632   \n",
    " 0.391304347826087   \n",
    " 0.391304347826087<br>                  </td><td>0.7444444444444445    \n",
    " 0.6    <br>\n",
    " 0.5444444444444444    \n",
    " 0.5166666666666667 <br>   \n",
    " 0.5    <br>\n",
    " 0.5        <br>       </td><td>0.7444444444444445    \n",
    " 0.6166666666666667    \n",
    " 0.5460526315789473    \n",
    " 0.5165165165165165    \n",
    " 0.4390243902439025    \n",
    " 0.4390243902439025           </td></tr>\n",
    "<tr><td>best_available_techniques_best_environmental_practices_bat_bep</td><td style=\"text-align: right;\">       16</td><td>AdaBoost    \n",
    " K Nearest Neighbor    \n",
    " Decsision Tree    \n",
    " Stochastic Gradient Descent    \n",
    " Gaussian Naive Bayes    \n",
    " Random Forest              </td><td>0.8695652173913043    \n",
    " 0.8260869565217391    \n",
    " 0.7391304347826086    \n",
    " 0.782608695652174    \n",
    " 0.782608695652174    \n",
    " 0.6956521739130435 <br>                </td><td>0.9210526315789473   \n",
    " 0.9   <br>\n",
    " 0.6919642857142857   \n",
    " 0.8809523809523809   \n",
    " 0.8809523809523809   \n",
    " 0.34782608695652173                  </td><td>0.7857142857142857    \n",
    " 0.7142857142857143    \n",
    " 0.6919642857142857    \n",
    " 0.6428571428571428    \n",
    " 0.6428571428571428 <br>   \n",
    " 0.5               <br></td><td>0.8207792207792208    \n",
    " 0.7444444444444445    \n",
    " 0.6919642857142857    \n",
    " 0.6546546546546547    \n",
    " 0.6546546546546547    \n",
    " 0.41025641025641024           </td></tr>\n",
    "<tr><td>innovations_in_techniques_approaches                          </td><td style=\"text-align: right;\">       15</td><td>Gaussian Naive Bayes    \n",
    " Stochastic Gradient Descent    \n",
    " Random Forest    \n",
    " K Nearest Neighbor    \n",
    " AdaBoost    \n",
    " Decsision Tree              </td><td>0.8695652173913043    \n",
    " 0.8695652173913043    \n",
    " 0.8695652173913043    \n",
    " 0.8260869565217391    \n",
    " 0.782608695652174    \n",
    " 0.7391304347826086                 </td><td>0.7236842105263157   \n",
    " 0.43478260869565216   \n",
    " 0.43478260869565216   \n",
    " 0.4318181818181818   \n",
    " 0.42857142857142855 <br>  \n",
    " 0.425      <br>            </td><td>0.7833333333333333    \n",
    " 0.5    <br>\n",
    " 0.5    <br>\n",
    " 0.475    <br>\n",
    " 0.45   <br> \n",
    " 0.425   <br>            </td><td>0.7472527472527473    \n",
    " 0.46511627906976744    \n",
    " 0.46511627906976744    \n",
    " 0.4523809523809524    \n",
    " 0.4390243902439024    \n",
    " 0.425           </td></tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
